{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project_Multi_Augmentation_PCA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9635-rRaNaHB",
        "q33OJ0hJqoIs",
        "fkzO1gNx5Tgd",
        "ErKErG555xGZ",
        "bGhn4vnO6K3l",
        "P74ZUthv62Vo",
        "6UhhU-hY7Mbk",
        "Lo6UwJM9wEYU",
        "rRBCrG0g7rVW",
        "TqySfVdpCoE3",
        "ObS0nyN5H1qb",
        "NI8OmhDlIt-f",
        "rkLrc60EJA6i",
        "0vGBC_OpTUVh",
        "h9dDOrzmTUVj",
        "xYt1DfSdTUVj",
        "qonY4zaqTUVk",
        "LNm5XLjbgICM"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfulVdlqeDUb"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P_KLNhChx4e",
        "scrolled": true
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(font_scale=1.0, style=\"dark\")\n",
        "import warnings \n",
        "from sklearn.svm import SVC, NuSVC\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors  import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "from scipy import stats\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
        "# from tflearn.data_utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy import interp\n",
        "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsIelASieMjL"
      },
      "source": [
        "# Data Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZWa0WB5N06M"
      },
      "source": [
        "## Make 1 or True  if you run colab\n",
        "## Other wise 0 or False\n",
        "##if you run in  colab\n",
        "\n",
        "colab = 0\n",
        "if colab ==True:\n",
        "  data_dir='/content/drive/MyDrive/PIMA Journal/diabetes.csv'\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  \n",
        "  data_dir='Diabetes_processed.csv'\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPXAbwA7Olty"
      },
      "source": [
        "data = pd.read_csv(data_dir)\n",
        "all_clf_res = {\n",
        "               'BloodPressure':[],\n",
        "               'Glucose':[]\n",
        "}"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fsEN6pCHOtDa",
        "outputId": "3595c099-8329-40a5-bca6-74a9aa0dd8e5"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>32.059259</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>27.094512</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction   Age  Outcome\n",
              "0          6.0    148.0           72.0  ...                     0.627  50.0        1\n",
              "1          1.0     85.0           66.0  ...                     0.351  31.0        0\n",
              "2          8.0    183.0           64.0  ...                     0.672  32.0        1\n",
              "3          1.0     89.0           66.0  ...                     0.167  21.0        0\n",
              "4          5.0    116.0           74.0  ...                     0.201  30.0        0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FBYD-y5pmde"
      },
      "source": [
        "def swap_col(target_):\n",
        "  swap_data = copy.deepcopy(data)\n",
        "  swap_data[target_] = data.Outcome\n",
        "  swap_data.Outcome = data[target_]\n",
        "  swap_data.rename(columns = {'Outcome':target_, target_: 'Diabetic'}, inplace = True)\n",
        "  #swap_data.Diabetic.replace({1:'Yes', 0:'No'} , inplace = True)\n",
        "  return swap_data"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EcVLsoXqcT0"
      },
      "source": [
        "data_BP = swap_col('BloodPressure')\n",
        "\n",
        "#data_ST = swap_col('SkinThickness')\n",
        "#data_Ins = swap_col('Insulin')\n",
        "#data_BMI = swap_col('BMI')\n",
        "#data_DPF = swap_col('DiabetesPedigreeFunction')\n",
        "#data_Age = swap_col('Age')\n",
        "#data_Pregnancies = swap_col('Pregnancies')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7g6m-qlyhx4u",
        "outputId": "fa0dbc4d-16b3-459c-9c37-032b7987dee5"
      },
      "source": [
        "data_BP.head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>Diabetic</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>BloodPressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50.0</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31.0</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>1</td>\n",
              "      <td>32.059259</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21.0</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.094512</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30.0</td>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  ...   Age  BloodPressure\n",
              "0          6.0    148.0  ...  50.0           72.0\n",
              "1          1.0     85.0  ...  31.0           66.0\n",
              "2          8.0    183.0  ...  32.0           64.0\n",
              "3          1.0     89.0  ...  21.0           66.0\n",
              "4          5.0    116.0  ...  30.0           74.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSG-nEalhx4w"
      },
      "source": [
        "knn_res = pd.DataFrame()\n",
        "random_initializer=100            #random initializer\n",
        "n_dots=50"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9635-rRaNaHB"
      },
      "source": [
        "# Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PneAZ5Jhx4x"
      },
      "source": [
        "def metrics (y_true, y_pred, probas_, tprs, mean_fpr):\n",
        "  '''\n",
        "  Parameters :\n",
        "  Input - \n",
        "  y_true - true  value of input data    \n",
        "  y_pred- predicted  value of input data  \n",
        "  probas_- probability/confidence of predicted output\n",
        "\n",
        "  return -True Negative(tn),False Positive(fp),False Negative(fn)\n",
        "  True positive(tp),AUC(roc_auc),False Positive Rate(fpr),\n",
        "  True positive rate(tpr)\n",
        "\n",
        "  '''\n",
        "\n",
        "\n",
        "  points=n_dots*'-'\n",
        "  print(points)\n",
        "#    print(\"Best parameters set found on development set:\")\n",
        "#    print(clf.best_params_)\n",
        "  #fpr, tpr, thresholds = roc_curve(y_true, probas_[:, 1])\n",
        "  #tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "  #tprs[-1][0] = 0.0\n",
        "  #roc_auc = auc(fpr, tpr)\n",
        "  #  aucs.append(roc_auc)\n",
        "  print(\"Detailed classification report for current fold:\")\n",
        "  print()\n",
        "  print(classification_report(y_true, y_pred))\n",
        "  print()\n",
        "  #print(\"Area Under ROC (AUC): {}\".format(roc_auc))\n",
        "  print()\n",
        "  print('Confusion Matrix for current fold: ')\n",
        "  print(confusion_matrix(y_true, y_pred))\n",
        "  print()\n",
        "  print(\"Accuracy for Current Fold: {}\".format(accuracy_score(y_true, y_pred)))\n",
        "  print()\n",
        "  confusion_array = multilabel_confusion_matrix(y_true, y_pred)\n",
        "  confusion_d = pd.DataFrame(confusion_array.reshape(-1, 4), columns=[\"TN\", \"FP\", \"FN\", \"TP\"])\n",
        "  tn, fp, fn, tp = np.array(confusion_d.TN), np.array(confusion_d.FP), np.array(confusion_d.FN), np.array(confusion_d.TP)\n",
        "\n",
        "  return  tn, fp, fn, tp\n",
        "\n",
        "#*******************************************************************************#\n",
        "\n",
        "def plot_Current_ROC(fpr,tpr,iterator,roc_auc):\n",
        "  \n",
        "  '''\n",
        "  Parameters :\n",
        "  Input - \n",
        "  fpr - False positive rate\n",
        "  tpr - True positive rate\n",
        "  roc_auc -auc values of roc curve\n",
        "\n",
        "  Output - \n",
        "  Visalization of current roc curve\n",
        "\n",
        "  '''\n",
        "  plt.plot(fpr,\n",
        "          \n",
        "          tpr,\n",
        "          # Color[iterator],\n",
        "          alpha=0.35,\n",
        "          # label='macro-average ROC (AUC = {0:0.3f})'.format(roc_auc)\n",
        "          # +FOLD[iterator],\n",
        "          linewidth=1)\n",
        "  \n",
        "\n",
        "#*******************************************************************************#\n",
        "   \n",
        "def average_ROC(mean_fpr,tprs,aucs,TP,TN,FP,FN):\n",
        "\n",
        "  '''\n",
        "  Parameters :\n",
        "  mean_fpr - Mean False positive rate\n",
        "  tprs -values of true positive rate\n",
        "  aucs  - values of auc\n",
        "  TP    - True positive \n",
        "  TN    - True Negative\n",
        "  FP    - False Positiv\n",
        "  FN    - False Negative\n",
        "\n",
        "  Output - \n",
        "  Visalization of TPR vs FPR plot\n",
        "  '''\n",
        "  sen = (np.sum(TP))/(np.sum(TP)+np.sum(FN))\n",
        "  spe = (np.sum(TN))/(np.sum(TN)+np.sum(FP))\n",
        "\n",
        "  mean_tpr = np.mean(tprs, axis=0)\n",
        "  mean_tpr[-1] = 1.0\n",
        "  # mean_auc = auc(mean_fpr, mean_tpr)\n",
        "  mean_auc = np.mean(aucs)\n",
        "  std_auc = np.std(aucs)\n",
        "  # plt.figure(figsize=(8, 5))\n",
        "  # plt.grid(True)\n",
        "  ax = plt.axes()\n",
        "  ax.grid(color='lightgray', linestyle='-', linewidth=.5)\n",
        "  # Setting the background color\n",
        "  ax.set_facecolor(\"white\")\n",
        "  \n",
        "  ax.spines['bottom'].set_color('#000000')\n",
        "  ax.spines['top'].set_color('#000000') \n",
        "  ax.spines['right'].set_color('#000000')\n",
        "  ax.spines['left'].set_color('#000000')\n",
        "\n",
        "  plt.plot(mean_fpr, mean_tpr, color='blue',\n",
        "          label=r'Avg. ROC (AUC (avg $\\pm$ std) = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
        "          lw=2, alpha=.8)\n",
        "  \n",
        "  plt.scatter((1-spe), sen, s=80, c='r', marker='x',)\n",
        "  plt.scatter(0, sen, s=80, c='r', marker='x',)\n",
        "  plt.scatter((1-spe),0, s=80, c='r', marker='x',)\n",
        "  plt.axhline(y=sen, color='r', linestyle='--')\n",
        "  plt.axvline(x=(1-spe), color='r', linestyle='--')\n",
        "  plt.text((1-spe), 0.02, \"FPR={:0.3f}\".format((1-spe)))\n",
        "  plt.text(0.009, sen+0.05, \"TPR={:0.3f}\".format(sen))\n",
        "\n",
        "  std_tpr = np.std(tprs, axis=0)\n",
        "  tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "  tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "  plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='darkgray', alpha=0.5,\n",
        "                  label=r'$\\pm$ 1 Standard deviation')\n",
        "\n",
        "  plt.xticks(np.arange(0.0, 1.01, step=0.1))\n",
        "  plt.yticks(np.arange(0.0, 1.01, step=0.1))\n",
        "  left=0.0\n",
        "  right=1.0\n",
        "  plt.xlim(left, right)\n",
        "  plt.ylim(left, right)\n",
        "  plt.xlabel('False Positive Rate (FPR)')\n",
        "  plt.ylabel('True Positive Rate (TPR)')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  # plt.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "#*******************************************************************************#\n",
        "\n",
        "def average_performance(Accuracy,TP,TN,FP,FN, target_col): \n",
        "\n",
        "  '''\n",
        "  Parameters :\n",
        "  Input - \n",
        "  Accuracy - value of accuracy\n",
        "  TP  - True Positive\n",
        "  TN  - True Negative\n",
        "  FP  - False Positive\n",
        "  FN  - False Negative\n",
        "\n",
        "\n",
        "  Output - \n",
        "  It prints the average accuarcy,confusion matrix\n",
        "  '''\n",
        "\n",
        "  print()\n",
        "  n_dotsav=(n_dots-len('Average'))//2\n",
        "    \n",
        "  print('-'*n_dotsav+'Average'+'-'*n_dotsav)\n",
        "  #print(\"AUC (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(aucs),np.std(aucs)))\n",
        "  print(\"Accuracy (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(Accuracy),np.std(Accuracy)))\n",
        "  cm = [[int(np.mean(TP)), int(np.mean(FP))],[int(np.mean(FN)), int(np.mean(TN))]]\n",
        "  print ('Avg. CM is '+str(cm))\n",
        "  cm = [[int(np.sum(TP)), int(np.sum(FP))],[int(np.sum(FN)), int(np.sum(TN))]]\n",
        "  print ('Total for all folds CM is '+str(cm))\n",
        "  #re_auc=str(round(np.mean(aucs), 3))+'+/-'+str(round(np.std(aucs),3))\n",
        "  re_accuracy=str(round(np.mean(Accuracy), 3))+'+/-'+str(round(np.std(Accuracy),3))\n",
        "  all_clf_res[target_col].append(re_accuracy)\n",
        "\n",
        "def creat_Model (classifier, X_Train, Y_Train, tuned_parameters, verbose):\n",
        " \n",
        "    clf = GridSearchCV(classifier,\n",
        "                    tuned_parameters,\n",
        "                    verbose=verbose,\n",
        "                    cv=5,\n",
        "                    scoring='accuracy',\n",
        "                    n_jobs=-1)\n",
        "    clf.fit(X_Train, Y_Train)\n",
        "    return clf\n",
        "\n",
        "#*******************************************************************************#\n",
        "    \n",
        "def feature_Selector(data, algo, n_feature):\n",
        " \n",
        "    if algo=='PCA':                                                   #for pca algorithm\n",
        "        X_Data= data.iloc[:,:8].values\n",
        "        pca = PCA(n_components=n_feature)                             #number of feature\n",
        "        X_Data = pca.fit_transform(X_Data)\n",
        "        return X_Data , data.iloc[:,8:].values\n",
        " \n",
        "    if algo == 'ICA':\n",
        "        X_Data= data.iloc[:,:8].values\n",
        "        ICA = FastICA(n_components=n_feature, random_state=12) \n",
        "        X_Data = ICA.fit_transform(X_Data)\n",
        "        return X_Data , data.iloc[:,8:].values\n",
        "    \n",
        "    if algo =='corr':                                                   #for ica algorithm\n",
        "        if n_feature ==4:\n",
        "            data = data[['F2','F5','F4','F6','Outcome']]                #for 4 feature\n",
        "            return data.iloc[:,:4].values, data.iloc[:,4:].values\n",
        "        if n_feature ==6:\n",
        "            data = data[['F1','F2','F4','F5','F6','F8','Outcome']]       #for 6 feature\n",
        "            return data.iloc[:,:6].values, data.iloc[:,6:].values\n",
        "        \n",
        "    if algo == 'None':\n",
        "        return data.iloc[:,:8].values, data.iloc[:,8:].values            #if feature selection is off all features are counted\n",
        "\n",
        "#*******************************************************************************#"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb_v6Fnqhx40"
      },
      "source": [
        "kf = StratifiedKFold(n_splits=5,\n",
        "                     shuffle=True,\n",
        "                     random_state=random_initializer)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfYhdL_AN9i1"
      },
      "source": [
        "# **Classifiers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q33OJ0hJqoIs"
      },
      "source": [
        "## KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1257TzEqoIw",
        "scrolled": true
      },
      "source": [
        "def clf_KNN(X_Data, Y_Lavel, target_col):\n",
        "\n",
        "    Accuracy = []                                                                # for store the value of accuracy \n",
        "    FP = []                                                                      # for store False Positive \n",
        "    TN = []                                                                      # for True Negative\n",
        "    FN = []                                                                      # for False Negative\n",
        "    TP = []                                                                      # for True Positive\n",
        "    tprs = []                                                                    # for true positive rates\n",
        "    aucs_kNN = []                                                                # for store the values of auc\n",
        "    iterator=0\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    fig = plt.figure(figsize=(8, 5))\n",
        "\n",
        "    for train_index, test_index in kf.split(X_Data,Y_Lavel):                     # split in train and test\n",
        "        #   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "        X_Train, X_Test = X_Data[train_index], X_Data[test_index]                #train data and label\n",
        "        Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]              #test data and label\n",
        "\n",
        "        ###########################################\n",
        "        # define the hyper parameters of Knn\n",
        "        n_neighbors = [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49]\n",
        "        leaf_size = [5,10,15,20,25,30,35,40,45,50]\n",
        "        Distance = [1,2]\n",
        "        ############################################\n",
        "\n",
        "\n",
        "        tuned_parameters = [ {'n_neighbors': n_neighbors,                         #define parameters with different algorithm\n",
        "                            'algorithm' : ['brute'],\n",
        "                            'p':Distance},\n",
        "\n",
        "                            {'n_neighbors': n_neighbors, \n",
        "                            'algorithm' : ['ball_tree'],\n",
        "                            'leaf_size' : leaf_size,\n",
        "                            'p':Distance},\n",
        "\n",
        "                            {'n_neighbors': n_neighbors, \n",
        "                            'algorithm' : ['kd_tree'],\n",
        "                            'leaf_size' : leaf_size,\n",
        "                            'p':Distance}]\n",
        "\n",
        "        clf = creat_Model (classifier = KNeighborsClassifier(),                     #create the model \n",
        "                          X_Train = X_Train,\n",
        "                          Y_Train = Y_Train,\n",
        "                          tuned_parameters = tuned_parameters,\n",
        "                          verbose=0)\n",
        "\n",
        "        tn, fp, fn, tp = metrics (y_true = Y_Test,               #get the values of  model evaluation \n",
        "                                          y_pred = clf.predict(X_Test),\n",
        "                                          probas_ = clf.predict_proba(X_Test), \n",
        "                                          tprs = tprs,\n",
        "                                          mean_fpr = mean_fpr)\n",
        "        #tprs.append(interp(mean_fpr, fpr, tpr))                                     \n",
        "        #tprs[-1][0] = 0.0\n",
        "        #aucs_kNN.append(roc_auc)\n",
        "        #plot_Current_ROC (fpr,tpr,iterator,roc_auc)                                 #plot the roc of current fold\n",
        "        iterator += 1\n",
        "        plot_confusion_matrix(clf, X_Test, Y_Test)\n",
        "        TN.append(tn)\n",
        "        FP.append(fp)\n",
        "        FN.append(fn)\n",
        "        TP.append(tp)\n",
        "        Accuracy.append(accuracy_score(Y_Test, clf.predict(X_Test)))\n",
        "    #average_ROC(mean_fpr,tprs,aucs_kNN,TP,TN,FP,FN)                                 #plot average roc curve\n",
        "    average_performance(Accuracy,TP,TN,FP,FN, target_col)                  #print the average performance of the model   "
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkzO1gNx5Tgd"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1ynAB2l5eHZ"
      },
      "source": [
        "def clf_DT(X_Data, Y_Lavel, target_col):\n",
        "\n",
        "  Accuracy = []                                                                # for store the value of accuracy \n",
        "  FP = []                                                                      # for store False Positive \n",
        "  TN = []                                                                      # for True Negative\n",
        "  FN = []                                                                      # for False Negative\n",
        "  TP = []                                                                      # for True Positive\n",
        "  tprs = []                                                                    # for true positive rates\n",
        "  aucs_Tree = []                                                               # for store the values of auc of tree model\n",
        "  iterator=0\n",
        "  mean_fpr = np.linspace(0, 1, 100)\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "\n",
        "  for train_index, test_index in kf.split(X_Data,Y_Lavel):\n",
        "      #   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_Train, X_Test = X_Data[train_index], X_Data[test_index]\n",
        "      Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]\n",
        "\n",
        "                                                                              # define the decision tree parameters \n",
        "\n",
        "      tuned_parameters = {'criterion': ['gini','entropy'],\n",
        "                        'splitter': ['best'],\n",
        "                        'min_samples_split':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
        "                        'min_samples_leaf': [1,2,3,4,5] }\n",
        "\n",
        "      clf = creat_Model (classifier = DecisionTreeClassifier( random_state=random_initializer),\n",
        "                        X_Train = X_Train,                                    # create the model using DecisionTree Classifier \n",
        "                        Y_Train = Y_Train,\n",
        "                        tuned_parameters = tuned_parameters,\n",
        "                        verbose=0)\n",
        "\n",
        "      tn, fp, fn, tp  = metrics (y_true = Y_Test,           #get the evaluation parameters of model\n",
        "                                y_pred = clf.predict(X_Test),\n",
        "                                probas_ = clf.predict_proba(X_Test),\n",
        "                                tprs = tprs, \n",
        "                                mean_fpr = mean_fpr)\n",
        "      #tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "      #tprs[-1][0] = 0.0\n",
        "      #aucs_Tree.append(roc_auc)                                                # plot the roc of current fold\n",
        "      iterator += 1\n",
        "      TN.append(tn)\n",
        "      FP.append(fp)\n",
        "      FN.append(fn)\n",
        "      TP.append(tp)\n",
        "      Accuracy.append(accuracy_score(Y_Test, clf.predict(X_Test)))\n",
        "  #average_ROC(mean_fpr,tprs,aucs_Tree,TP,TN,FP,FN)                             #plot average roc curve\n",
        "  average_performance(Accuracy,TP,TN,FP,FN, target_col)                          #print the average performance of the model"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErKErG555xGZ"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKmfWVqn54Yg"
      },
      "source": [
        "def clf_RF(X_Data, Y_Lavel, target_col):\n",
        "  Accuracy = []                                                                # for store the value of accuracy \n",
        "  FP = []                                                                      # for store False Positive \n",
        "  TN = []                                                                      # for True Negative\n",
        "  FN = []                                                                      # for False Negative\n",
        "  TP = []                                                                      # for True Positive\n",
        "  tprs = []                                                                    # for true positive rates\n",
        "  aucs_Forest = []                                                             # for store the values of auc of Random Forest model\n",
        "  iterator=0\n",
        "  mean_fpr = np.linspace(0, 1, 100)\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "\n",
        "  for train_index, test_index in kf.split(X_Data,Y_Lavel):                     #split dataset into train /test\n",
        "  #   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_Train, X_Test = X_Data[train_index], X_Data[test_index]                # data and label of train dataset\n",
        "      Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]              # data and label of test dataset\n",
        "\n",
        "      # parameters of Random Forest model\n",
        "      tuned_parameters = {'criterion': ['gini','entropy']}\n",
        "\n",
        "      clf = creat_Model (classifier = RandomForestClassifier( random_state=random_initializer),\n",
        "                        X_Train = X_Train,                                      # create a model using random forest classifier\n",
        "                        Y_Train = Y_Train,\n",
        "                        tuned_parameters = tuned_parameters,\n",
        "                        verbose=0)\n",
        "\n",
        "      tn, fp, fn, tp = metrics (y_true = Y_Test,              #evaluation parameters of random forest model\n",
        "                                y_pred = clf.predict(X_Test),\n",
        "                                probas_ = clf.predict_proba(X_Test),\n",
        "                                tprs = tprs, \n",
        "                                mean_fpr = mean_fpr)\n",
        "      \n",
        "      #tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "      #tprs[-1][0] = 0.0\n",
        "      #aucs_Forest.append(roc_auc)\n",
        "      #plot_Current_ROC (fpr,tpr,iterator,roc_auc)                               #plot the roc of current fold\n",
        "      iterator += 1\n",
        "      TN.append(tn)\n",
        "      FP.append(fp)\n",
        "      FN.append(fn)\n",
        "      TP.append(tp)\n",
        "      Accuracy.append(accuracy_score(Y_Test, clf.predict(X_Test)))\n",
        "  #average_ROC(mean_fpr,tprs,aucs_Forest,TP,TN,FP,FN)                            #plot average roc curve\n",
        "  average_performance(Accuracy,TP,TN,FP,FN, target_col)                         #print the average performance of the model"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGhn4vnO6K3l"
      },
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SfVImwq6WGh"
      },
      "source": [
        "def clf_AB(X_Data, Y_Lavel, target_col):\n",
        "  Accuracy = []                                                                # for store the value of accuracy \n",
        "  FP = []                                                                      # for store False Positive \n",
        "  TN = []                                                                      # for True Negative\n",
        "  FN = []                                                                      # for False Negative\n",
        "  TP = []                                                                      # for True Positive\n",
        "  tprs = []                                                                    # for true positive rates\n",
        "  aucs_aBoost = []                                                             # for store the values of auc of Adaboost model\n",
        "  iterator=0\n",
        "\n",
        "  mean_fpr = np.linspace(0, 1, 100)\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "\n",
        "\n",
        "  for train_index, test_index in kf.split(X_Data,Y_Lavel):                     #split into train and test \n",
        "      #   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_Train, X_Test = X_Data[train_index], X_Data[test_index]                #data and label\n",
        "      Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]              #data and label\n",
        "\n",
        "      #####################################################\n",
        "      # define the parameters of adaboost algorithm\n",
        "      #####################################################\n",
        "      tuned_parameters = { 'algorithm': ['SAMME','SAMME.R'],\n",
        "                        'learning_rate':[0.1,0.5,1.0],\n",
        "                        'n_estimators': [10,50,100,200]}\n",
        "\n",
        "      \n",
        "      clf = creat_Model (classifier = AdaBoostClassifier( random_state=random_initializer),\n",
        "                        X_Train = X_Train,                                      # create a model using  AdaBoost Classifier\n",
        "                        Y_Train = Y_Train,\n",
        "                        tuned_parameters = tuned_parameters,\n",
        "                        verbose=0)\n",
        "      tn, fp, fn, tp = metrics (y_true = Y_Test,             # model evaluation parametrs\n",
        "                                y_pred = clf.predict(X_Test),\n",
        "                                probas_ = clf.predict_proba(X_Test),\n",
        "                                tprs = tprs, \n",
        "                                mean_fpr = mean_fpr)\n",
        "      #tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "      #tprs[-1][0] = 0.0\n",
        "      #aucs_aBoost.append(roc_auc)\n",
        "      #plot_Current_ROC (fpr,tpr,iterator,roc_auc)                              #plot the roc of current fold\n",
        "      iterator += 1\n",
        "      TN.append(tn)\n",
        "      FP.append(fp)\n",
        "      FN.append(fn)\n",
        "      TP.append(tp)\n",
        "      Accuracy.append(accuracy_score(Y_Test, clf.predict(X_Test)))\n",
        "  #average_ROC(mean_fpr,tprs,aucs_aBoost,TP,TN,FP,FN)                           #plot average roc curve\n",
        "  average_performance(Accuracy,TP,TN,FP,FN, target_col)                        #print the average performance of the model"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P74ZUthv62Vo"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGSIcPav67nG"
      },
      "source": [
        "def clf_NB(X_Data, Y_Lavel, target_col):\n",
        "  Accuracy = []                                                                # for store the value of accuracy \n",
        "  FP = []                                                                      # for store False Positive \n",
        "  TN = []                                                                      # for True Negative\n",
        "  FN = []                                                                      # for False Negative\n",
        "  TP = []                                                                      # for True Positive\n",
        "  tprs = []                                                                    # for true positive rates\n",
        "  aucs_NB = []                                                                 # for store the values of auc of  model\n",
        "  iterator=0\n",
        "\n",
        "  mean_fpr = np.linspace(0, 1, 100) \n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "\n",
        "\n",
        "  for train_index, test_index in kf.split(X_Data,Y_Lavel):                     #split into train and test\n",
        "  #   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_Train, X_Test = X_Data[train_index], X_Data[test_index]                #train data and label\n",
        "      Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]              #test  data and label\n",
        "\n",
        "\n",
        "      #############################################\n",
        "      # define parameters of Naive Bayes model \n",
        "      ############################################\n",
        "      var_smoothing = [1e-01,\n",
        "                      1e-02,\n",
        "                      1e-03,\n",
        "                      1e-04,\n",
        "                      1e-05,\n",
        "                      1e-06,\n",
        "                      1e-07,\n",
        "                      1e-08,\n",
        "                      1e-09,\n",
        "                      1e-10,\n",
        "                      1e-11,\n",
        "                      1e-12]\n",
        "\n",
        "      tuned_parameters = [{'var_smoothing': var_smoothing}]\n",
        "\n",
        "      #############################################################\n",
        "      clf = creat_Model (classifier = GaussianNB(),                             # create model using Naive Bias\n",
        "                        X_Train = X_Train,\n",
        "                        Y_Train = Y_Train,\n",
        "                        tuned_parameters = tuned_parameters,\n",
        "                        verbose=0)\n",
        "      tn, fp, fn, tp = metrics (y_true = Y_Test,             # model evaluation parameters\n",
        "                                y_pred = clf.predict(X_Test),\n",
        "                                probas_ = clf.predict_proba(X_Test),\n",
        "                                tprs = tprs, \n",
        "                                mean_fpr = mean_fpr)\n",
        "      #tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "      #tprs[-1][0] = 0.0\n",
        "      #aucs_NB.append(roc_auc)\n",
        "      #plot_Current_ROC (fpr,tpr,iterator,roc_auc)                               #plot the roc of current fold\n",
        "      iterator += 1\n",
        "      TN.append(tn)\n",
        "      FP.append(fp)\n",
        "      FN.append(fn)\n",
        "      TP.append(tp)\n",
        "      Accuracy.append(accuracy_score(Y_Test, clf.predict(X_Test)))\n",
        "  #average_ROC(mean_fpr,tprs,aucs_NB,TP,TN,FP,FN)                               #plot average roc curve\n",
        "  average_performance(Accuracy,TP,TN,FP,FN, target_col)                            #print the average performance of the model"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UhhU-hY7Mbk"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8XPonAI7XKk"
      },
      "source": [
        "def clf_XGB(X_Data, Y_Lavel, target_col):\n",
        "  Accuracy = []                                                                # for store the value of accuracy \n",
        "  FP = []                                                                      # for store False Positive \n",
        "  TN = []                                                                      # for True Negative\n",
        "  FN = []                                                                      # for False Negative\n",
        "  TP = []                                                                      # for True Positive\n",
        "  tprs = []                                                                    # for true positive rates\n",
        "  aucs_xboost = []                                                                # for store the values of auc\n",
        "  sn = []                                                                      # for sensitivity \n",
        "  sp = []                                                                      # for specificity\n",
        "  pr = []                                                                      # for precision\n",
        "  FOR = []                                                                     # for False omission rate \n",
        "  DOR = []                                                                     # for Diagnostic odds ratio (DOR)\n",
        "  iterator=0\n",
        "  mean_fpr = np.linspace(0, 1, 100)\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "\n",
        "\n",
        "  for train_index, test_index in kf.split(X_Data,Y_Lavel):                     # split into train and test\n",
        "  #   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_Train, X_Test = X_Data[train_index], X_Data[test_index]                #train data and label\n",
        "      Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]              #test data and label\n",
        "\n",
        "      #####################################\n",
        "      ## define the parameters \n",
        "      ######################################\n",
        "      tuned_parameters = {\n",
        "          'min_child_weight': [1, 5, 10],\n",
        "          'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "          'subsample': [0.5, 1.0],\n",
        "          'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "          'max_depth': [3, 4, 5]\n",
        "          }\n",
        "\n",
        "      clf = creat_Model (classifier = xgb.XGBClassifier(objective = \"multi:softprob\", eval_metric = 'merror', random_state=random_initializer),\n",
        "                        X_Train = X_Train,                                        # create model using XGB classifier \n",
        "                        Y_Train = Y_Train,\n",
        "                        tuned_parameters = tuned_parameters,\n",
        "                        verbose=0)\n",
        "      tn, fp, fn, tp  = metrics (y_true = Y_Test,               #evaluate the model parameters\n",
        "                        y_pred = clf.predict(X_Test),\n",
        "                        probas_ = clf.predict_proba(X_Test),\n",
        "                        tprs = tprs, \n",
        "                        mean_fpr = mean_fpr)\n",
        "      #tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "      #tprs[-1][0] = 0.0\n",
        "      #aucs_xboost.append(roc_auc)\n",
        "      #plot_Current_ROC(fpr,tpr,iterator,roc_auc)                                  #plot the roc of current fold \n",
        "      iterator += 1\n",
        "      TN.append(tn)\n",
        "      FP.append(fp)\n",
        "      FN.append(fn)\n",
        "      TP.append(tp)\n",
        "      Accuracy.append(accuracy_score(Y_Test, clf.predict(X_Test)))\n",
        "      sn.append(tp/(tp+fn))\n",
        "      sp.append(tn/(fp+tn))\n",
        "      pr.append(tp/(tp+fp))\n",
        "      FOR.append(fn/(tn+fn))\n",
        "      DOR.append((tp*tn)/(fp*fn))\n",
        "\n",
        "  #average_ROC(mean_fpr,tprs,aucs_xboost,TP,TN,FP,FN)                              #plot average roc curve\n",
        "  average_performance(Accuracy,TP,TN,FP,FN, target_col)               #print the average performance of the model\n",
        "\n",
        "  #####################################################################\n",
        "  #    print the sensitivity,specificity,precision,for,dor of model\n",
        "  #####################################################################\n",
        "  print(\"Sensitivity (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(sn),np.std(sn)))\n",
        "  print(\"Specificity (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(sp),np.std(sp)))\n",
        "  print(\"Precision (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(pr),np.std(pr)))\n",
        "  print(\"FOR (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(FOR),np.std(FOR)))\n",
        "  print(\"DOR (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(DOR),np.std(DOR)))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SsUKyeshx41"
      },
      "source": [
        "# With BloodPressure as Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr1VI20Utwf6",
        "scrolled": true,
        "outputId": "632fa442-cee9-472b-c750-80ef6478631f"
      },
      "source": [
        "data_BP.head(), data_BP.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   Pregnancies  Glucose  ...   Age  BloodPressure\n",
              " 0          6.0    148.0  ...  50.0           72.0\n",
              " 1          1.0     85.0  ...  31.0           66.0\n",
              " 2          8.0    183.0  ...  32.0           64.0\n",
              " 3          1.0     89.0  ...  21.0           66.0\n",
              " 4          5.0    116.0  ...  30.0           74.0\n",
              " \n",
              " [5 rows x 9 columns], (636, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1R64Mjrhx42"
      },
      "source": [
        "def categorize_BP(data_BP):\n",
        "    \n",
        "    BP = \"BloodPressure\"\n",
        "    try:\n",
        "        low_i = data_BP.loc[(data_BP[BP] <= 60)] #diastolic less than 80 is normal\n",
        "        normal_i = data_BP.loc[(data_BP[BP] > 60) & (data_BP[BP] < 80)] #diastolic between 60 and 80 is normal\n",
        "        high_i =  data_BP.loc[data_BP[BP] >= 80] #diastolic greater than 80 is high\n",
        " \n",
        "        data_BP[BP][low_i.index] = 0\n",
        "        data_BP[BP][normal_i.index] = 1\n",
        "        data_BP[BP][high_i.index] = 2\n",
        "     \n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return data_BP"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCUqhRgVhx43"
      },
      "source": [
        "data_BP = categorize_BP(data_BP)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "AYl_S6af28Pr",
        "outputId": "7343c925-fd97-49b8-cfd8-a3c22e9eee88"
      },
      "source": [
        "#Augmentation\n",
        "smote = SMOTE()\n",
        "X = np.array(data_BP.iloc[:,0:8])\n",
        "y = np.array(data_BP.iloc[:,8])\n",
        "X, y = smote.fit_resample(X, y)\n",
        "data_BP = pd.DataFrame(X)\n",
        "data_BP['BloodPressure'] = y\n",
        "data_BP.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>BloodPressure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>33.600000</td>\n",
              "      <td>0.627000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>26.600000</td>\n",
              "      <td>0.351000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>32.059259</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>23.300000</td>\n",
              "      <td>0.672000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>28.100000</td>\n",
              "      <td>0.167000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.094512</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>25.600000</td>\n",
              "      <td>0.201000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081</th>\n",
              "      <td>5.934270</td>\n",
              "      <td>105.039438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.881686</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>32.429011</td>\n",
              "      <td>0.871716</td>\n",
              "      <td>25.973708</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082</th>\n",
              "      <td>1.179441</td>\n",
              "      <td>77.764112</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.830657</td>\n",
              "      <td>40.471776</td>\n",
              "      <td>36.640523</td>\n",
              "      <td>0.368423</td>\n",
              "      <td>24.302434</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083</th>\n",
              "      <td>0.560337</td>\n",
              "      <td>86.034609</td>\n",
              "      <td>0.439663</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>36.560337</td>\n",
              "      <td>30.675957</td>\n",
              "      <td>0.435273</td>\n",
              "      <td>22.879326</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1084</th>\n",
              "      <td>1.206636</td>\n",
              "      <td>117.553549</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.206636</td>\n",
              "      <td>167.933642</td>\n",
              "      <td>43.874213</td>\n",
              "      <td>0.453068</td>\n",
              "      <td>26.413272</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1085</th>\n",
              "      <td>5.757954</td>\n",
              "      <td>103.121023</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>41.242046</td>\n",
              "      <td>181.827881</td>\n",
              "      <td>39.289956</td>\n",
              "      <td>0.910641</td>\n",
              "      <td>33.227698</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1086 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0           1         2  ...         6          7  BloodPressure\n",
              "0     6.000000  148.000000  1.000000  ...  0.627000  50.000000            1.0\n",
              "1     1.000000   85.000000  0.000000  ...  0.351000  31.000000            1.0\n",
              "2     8.000000  183.000000  1.000000  ...  0.672000  32.000000            1.0\n",
              "3     1.000000   89.000000  0.000000  ...  0.167000  21.000000            1.0\n",
              "4     5.000000  116.000000  0.000000  ...  0.201000  30.000000            1.0\n",
              "...        ...         ...       ...  ...       ...        ...            ...\n",
              "1081  5.934270  105.039438  0.000000  ...  0.871716  25.973708            2.0\n",
              "1082  1.179441   77.764112  0.000000  ...  0.368423  24.302434            2.0\n",
              "1083  0.560337   86.034609  0.439663  ...  0.435273  22.879326            2.0\n",
              "1084  1.206636  117.553549  0.000000  ...  0.453068  26.413272            2.0\n",
              "1085  5.757954  103.121023  1.000000  ...  0.910641  33.227698            2.0\n",
              "\n",
              "[1086 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9midecChx44",
        "outputId": "bddb4c24-1ce8-4e12-a782-64be4eb49461"
      },
      "source": [
        "data_BP.BloodPressure.value_counts()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    362\n",
              "0.0    362\n",
              "1.0    362\n",
              "Name: BloodPressure, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXpvMzadhx45"
      },
      "source": [
        "data_BP.columns = ['F' + str(i) for i in range(1,9)]+['Outcome'] #Renaming"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eerd4pjVhx45"
      },
      "source": [
        "X_Data,Y_Lavel = feature_Selector(data_BP, algo='PCA', n_feature=6)  "
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmLtRnM9hx45",
        "scrolled": true,
        "outputId": "b9caf28d-2f04-436d-e2fa-5c15a4654a0e"
      },
      "source": [
        "np.unique(Y_Lavel,return_counts = True)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1., 2.]), array([362, 362, 362]))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo6UwJM9wEYU"
      },
      "source": [
        "#### Analyzing **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ja0vlEwcIaEH",
        "outputId": "f4c3a69d-1ea4-472c-84be-003c59f68a9c"
      },
      "source": [
        "clf_KNN(X_Data, Y_Lavel, 'BloodPressure')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.88      0.82        72\n",
            "         1.0       0.79      0.42      0.55        73\n",
            "         2.0       0.64      0.86      0.74        73\n",
            "\n",
            "    accuracy                           0.72       218\n",
            "   macro avg       0.74      0.72      0.70       218\n",
            "weighted avg       0.74      0.72      0.70       218\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[63  3  6]\n",
            " [13 31 29]\n",
            " [ 5  5 63]]\n",
            "\n",
            "Accuracy for Current Fold: 0.7201834862385321\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.88      0.80        72\n",
            "         1.0       0.57      0.37      0.45        73\n",
            "         2.0       0.67      0.79      0.73        72\n",
            "\n",
            "    accuracy                           0.68       217\n",
            "   macro avg       0.66      0.68      0.66       217\n",
            "weighted avg       0.66      0.68      0.66       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[63  7  2]\n",
            " [20 27 26]\n",
            " [ 2 13 57]]\n",
            "\n",
            "Accuracy for Current Fold: 0.6774193548387096\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.95      0.80        73\n",
            "         1.0       0.74      0.40      0.52        72\n",
            "         2.0       0.72      0.78      0.75        72\n",
            "\n",
            "    accuracy                           0.71       217\n",
            "   macro avg       0.72      0.71      0.69       217\n",
            "weighted avg       0.72      0.71      0.69       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[69  2  2]\n",
            " [23 29 20]\n",
            " [ 8  8 56]]\n",
            "\n",
            "Accuracy for Current Fold: 0.7096774193548387\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.90      0.78        73\n",
            "         1.0       0.60      0.38      0.46        72\n",
            "         2.0       0.72      0.76      0.74        72\n",
            "\n",
            "    accuracy                           0.68       217\n",
            "   macro avg       0.67      0.68      0.66       217\n",
            "weighted avg       0.67      0.68      0.66       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[66  4  3]\n",
            " [27 27 18]\n",
            " [ 3 14 55]]\n",
            "\n",
            "Accuracy for Current Fold: 0.6820276497695853\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.86      0.77        72\n",
            "         1.0       0.73      0.44      0.55        72\n",
            "         2.0       0.71      0.82      0.76        73\n",
            "\n",
            "    accuracy                           0.71       217\n",
            "   macro avg       0.71      0.71      0.70       217\n",
            "weighted avg       0.71      0.71      0.70       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[62  5  5]\n",
            " [21 32 19]\n",
            " [ 6  7 60]]\n",
            "\n",
            "Accuracy for Current Fold: 0.7096774193548387\n",
            "\n",
            "\n",
            "---------------------Average---------------------\n",
            "Accuracy (Avg. +/- Std.) is  0.700 +/- 0.017\n",
            "Avg. CM is [[50, 21], [21, 123]]\n",
            "Total for all folds CM is [[760, 326], [326, 1846]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEMCAYAAAC4FB/6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxU9f4/8NfMsIk6jqDgACa5Rrk7pnk101T4Gcqtew2vpJblUmK2WYReVLQFtcXrcslry7UolW7aBRfQNs3Kpa+aSK4XNxhAQTIQWc45vz/QSQacMwhzzsC8nj3O4+HM+cxn3pxHvPl8zudzPh+NJEkSiIjIQqt2AEREzoaJkYjIChMjEZEVJkYiIitMjEREVpgYiYisMDESkaIksUjtEGRpmto8RrFgPCDmqh2GU5r8p15qh+D0pIoKtUNwam0CffDu94vrXU9lQaT876m2Hdx8N9T7u26Hmyrf6khiLiBkqx2FU8o7G6h2CE5PqihXOwSXIAg58r+nOlG1BNX0EiMROT3p+n+2aGTOOxITIxEpToQECaLNMkyMRORSKiURomQ7MWplzjsSEyMRKU6ABFGmRSjX1XYkJkYiUpxoR2IEEyMRuRJRkiDIzRRUcSYhEyMRKU68ftiiUSKQW2BiJCLFCZAgsCtNRPSHSqnqsEXNZ/KYGIlIcQI0EGQ6yxoVO9NMjESkOFGqOuTKqIWJkYgUJ9rRYtSyxUhErsSerjQTIxG5lEpJiwrJ9nKwGpnzjsTESESKE6CFILNOttx5a2VlZXj99dfx448/wtPTE71798aiRYuQlZWFmJgYFBUVwWAwICEhAcHBwTbrYmIkIsVVDb7Y7irXdfBl6dKl8PT0RFpaGjQaDS5dugQAmD9/PiZMmICIiAh8+eWXiIuLw7p162zWxa0NiEhxNwZfbB1iHe4xlpSUYPPmzZg9ezY0mqrPtWnTBgUFBcjMzER4eDgAIDw8HJmZmSgsLLRZH1uMRKQ4AVoIMvcQb3SlzWYzBEGodk6v10Ov11tenz9/HgaDAStXrsTevXvRvHlzzJ49G15eXvD394dOpwMA6HQ6+Pn5wWw2w8fH55bfzcRIRIoToYUo02G9cT4qKgrZ2dW3QYiOjsasWbMsrwVBwPnz53H33XfjlVdeweHDhzFjxgwsX778tuJjYiQixVVIWpRLOptltNdblElJSbW2GG9mNBrh5uZm6TL36tULrVu3hpeXF/Ly8iAIAnQ6HQRBQH5+PoxGo+3vrusPRERUX+L1e4hyB1CV9IKCgqod1onRx8cHAwYMwJ49ewAAWVlZKCgoQHBwMEJCQpCamgoASE1NRUhIiM1uNMAWIxGpQLRjuo5cV9vawoULERsbi4SEBLi5uWHJkiXQ6/VYsGABYmJisHr1auj1eiQkJMjWxcRIRIoTJDsGX+o4wbt9+/b4+OOPa7zfqVMnJCcn16kuJkYiUlxdBl/UwMRIRIoTJUBo4AneDYmJkYgUVyG5oUKynX7kzjsSEyMRKc4Rgy8NiYmRiBQnSBrZrrTceUdiYmxA32424JO32yE/2x0+fpV48d1z6DGgBNeuavCvRYHY9V8DKis16Hh3Kd7adErtcJ1CQPA1JKZl4PttrbHkuU5qh+M0Xl5xFr0HF8PLW8TlfDck/9MP2z/1VTusBlM1T1GuxegCidGepX8EQcDixYuxe/duaDQaTJs2DePGjVMqxHr5+bsWeP+1AMQmnkG3PldRmOduObf85fYQKjX4165f0dIg4H9Hm6kYqXOZuegsTvzSXO0wnM6GFf5458X2qCjXon3na1jy+WmcOtIMp454qx1agxDtmK4jqrgeo2LffGPpn7S0NEyYMAFxcXE1yqSkpODcuXNIT0/Hhg0bsGLFCly4cEGpEOvl42VGRD2fi5B+V6HVAm2MFWhjrMC5k574Kb0VZi89D4OvAJ0O6NKzVO1wncLQMQUouaLDoT16+cIu5uwJL1SUV/16SlLVERBcrnJUDadC0tl1qEWRxGjv0j9bt27FuHHjoNVq4ePjgxEjRmD79u1KhFgvggCc/KUZfitww+ODQhDV726sjA1EWakGxw95wy+oHB8va4dx93TH9OHdsHtLK7VDVp13CwETX8jGmkV3qB2K04p+/QK+PP0L3t99HIX57tj3VUu1Q2owVcuOaW0eTb4rbTab7Vr6x2w2IyAgwPLaaDQiNzdXiRDrpeiiGyortNi9xYC3Np2Em5uEBU/ciU+X+8PLW8SZY80wePRv+PTgUfz6szf+PrEjOnQ9gTu6lKkdumomvXgBaRva4lKuh9qhOK2VsUFYPS8QIaYS9LyvxNKCbApEaOQXqlUxMTadK60iD6+qmagRUy7C178SrXwFPDL9IvZ/pYenlwQ3dxETnsuFu4eEnveVoNegYvz8XdP5619XHe++ij6Dr2DT+/5qh+L0RFGDo/taoK2xAuGTL6kdToORay3as/WBIynSYjQajXYt/WM0GpGTk4OePXsCqNmCdFYtDQLaGMtx8x+464sI486QmvcTNer9IXQKPQdegX9QOdb9cBgA0Ky5CK1OwsouRxH90D0qR+ectG4SjB2azj1GSdLKDq5ITX3wxdfX166lf8LCwpCcnAxRFFFYWIidO3ciNDRUiRDrbVRkIf77QVsUXXLD70U6fLGmLQaMvIIeA4vRNrAC61f4Q6gEju5rjsM/tEC/ob+rHbJqtn3aFk/c3xMzR3fHzNHdsSWpLfZ9bcDciV3VDs0ptPKtwNCIy/DyFqDVSug39AqG/bkIh75voXZoDUZuWwN7tld1JMWm69xq6Z+pU6fi2WefRY8ePRAREYHDhw9j1KhRAICZM2eiffv2SoVYL1HP5+LKZTdMGRwCD08R948pwt+ezYObO7Dgwyy8+1J7bFjpB/+gCsz5xzmXvr9Ydk2Hsmt/jDheK9GhokyD3wrdbXzKhUgahE8qwLNvXoBGC+Rf8EBiXAB+Sm86g3ZV26faHnWuVLHFqJEkScVHtRueePEBQMiWLeeKwjrcq3YITk+qaDrdVUfw79AWn2Strnc9K09MwW8V+TbLtHL3Q3TXD+r9XbeDT74QkeIcsR5jQ2JiJCLFSXZsjyq5wj1GIqIbqhaRkGsxMjESkQsRJTsmeDMxEpErqbTjWehKFZ+VZmIkIsVxzxciIisC7FioloMvRORKJEn+HqKaM6yZGIlIcaIdz0qruVAtEyMRKa7qkUDbiU/NRwKZGIlIcY5oMQ4fPhweHh7w9PQEALz00ksYMmQIDh06hLi4OJSVlSEwMBBLly6Fr6/t/XOYGIlIcaIdT77czkK1//jHP9C16x+rNImiiDlz5uCNN96AyWTC6tWrsWzZMrzxxhs26+FCtUSkOEH6YwvVWx/1/56MjAx4enrCZDIBAMaPH2/XdilsMRKR4uqyUK3ZbIYgCNXO6fV66PU1N1F76aWXIEkS+vXrhxdeeKHGYtc+Pj4QRdGyW+mtMDESkeLq8khgVFQUsrOrLyUYHR2NWbNmVXsvKSkJRqMR5eXleO211xAfH4+RI0feVnxMjESkuEpoZUedK6/f6UtKSqq1xWjtxlYpHh4emDBhAp5++mlMmjQJOTk5ljKFhYXQarU2W4sAEyMRqaAuXWnrvaFqc/XqVQiCgJYtW0KSJGzduhUhISHo3r07rl27hgMHDsBkMmH9+vUICwuTrY+JkYgUJ9rx5ItYh8GXgoICzJo1C4IgQBRFdOrUCfPnz4dWq8WSJUswf/78atN15DAxEpHiGnq6Tvv27bF58+Zaz/Xt2xcpKSl1io+JkYgUx/UYiYisSHYkRomJkYhcSaWoRaUoMyotc96RmBiJSHGOeiSwoTAxEpHi2JUmIrIiwo7pOsqEUismRiJSHEeliYisiKIWgszgisjBFyJyJRx8ISKywq40EZEVSdLIjjpzVJqIXApbjAoLWzMROZevqB2Gc5olX8TVtT5RqXYITq3Mr+Y6iLdFsqNFyH2liciVCJIGgmg7MQpsMRKRK+GoNBGRFQ6+EBFZ4bPSRERWJKnqkCujFiZGIlIcu9JERFYEO56VljvvSEyMRKQ4CXZ0pRWJpHa3TIxz5syBRiPflF2yZEmDBkRETZ9kxwRvp7zH2KFDByXjICJXYsc9RjjjPcbo6Ggl4yAiFyJBvqvslF1pa3v27MGWLVtQWFiIxMREHDlyBMXFxbjvvvscGR8RNUGSqIEk80ig3HlHsmvY5+OPP8aCBQsQHByM/fv3AwC8vLywfPlyhwZHRE3Tjek6coda7EqM//73v/Hhhx9i2rRp0GqrPtKxY0dkZWU5NDgiappuTPCWO27HypUr0a1bN5w4cQIAcOjQIYwdOxahoaGYMmUKCgoKZOuwKzGWlJTAaDQCgGWkurKyEu7u7rcXORG5NEe1GI8ePYpDhw4hMDAQACCKIubMmYO4uDikpaXBZDJh2bJlsvXYlRj79++PNWvWVHtv3bp1GDBgQJ0DJyICNFWjzraOOq6uU15ejvj4eCxYsMDyXkZGBjw9PWEymQAA48ePx/bt22XrsmvwZd68eZgxYwaSk5NRUlKC0NBQNG/eHO+9916dAiciAur2rLTZbIYgCNXO6fV66PXVF81dvnw5xo4di6CgIMt7ZrMZAQEBltc+Pj4QRRFFRUUwGAy3/G67EqOfnx/+85//4MiRI8jOzobRaETPnj0t9xuJiOqiLqPSUVFRyM7OrnYuOjoas2b9sST9wYMHkZGRgZdeeqlB4rN7uo4oiqioqAAACIIASc1p6UTUuNVhImNSUlKtLcab7d+/H6dPn8aDDz4IAMjNzcWTTz6JiRMnIicnx1KusLAQWq3WZmsRsDMxHjt2DDNnzkR5eTn8/f2Rm5sLT09PrFq1CnfddZc9VRAR/aEOT77cGPi1Zdq0aZg2bZrl9fDhw5GYmIjOnTtj48aNOHDgAEwmE9avX4+wsDDZ+uxKjLGxsYiKisITTzwBjUYDSZLw0UcfITY2Fl988YU9VRAR/UGhR1+0Wi2WLFmC+fPno6ysDIGBgVi6dKns5+xKjGfOnMHkyZMtU3U0Gg0mTZqEFStW1C9qInJhjpvA/fXXX1v+3bdvX6SkpNTp83aNngwdOrTaFwHAN998gwceeKBOX0ZEBKCqNSjKHM64us7Ny44JgoDnn38e3bt3R7t27ZCbm4uMjAzLjU4iojqxzFWUKaMSu5cd69q1q+XfnTt3xuDBgx0XFRE1aY12zxcuO0ZEDuPk647ZPY+xvLwcWVlZuHz5crU5jFx2jIjqrLF2pW924MABPPfccygvL0dxcTFatGiBkpIStGvXDl999ZWjYySiJkYjVR1yZdRiV2J844038NRTT+Hxxx9H//79sW/fPqxcuRLNmjVzdHxE1BSJmqpDroxK7Jquc+bMGUyaNKnae9OmTcNHH33kiJiIyBVIMoeK7GoxtmzZEsXFxdDr9Wjbti1OnToFg8GAq1evOjq+RsFdJ2DuiF0Y2OECWnmV4XyRHv/YPQDfZ3XA6JATiBv5naWsRgM0c69E5Md/xa95bVWMWjm8PvIeHnYUYfedQMfAQny1vxPe/OgBy7lh/U7jibH/h7atS5Bf2Bz/2twf3x8KVi3WBtEUBl9GjhyJ7777DmPGjMFf/vIXTJo0CW5ubggNDXV0fI2Cm1ZE3u8tMGV9BMxXWmJIx7NYOmYH/vLRo9j6a1ds/fWPqU5j7zmG6ff9jF/z2qgYsbJ4feRdKvLGx1v74N67L8DDo9LyfhtDCeY++S3mrh6FvRlBGNjjPBZO34nIV/+Got8b8a2sppAY586da/n3k08+iV69eqGkpARDhgyx60sSEhKQlpaG7OxspKSkVJsTeYMgCFi8eDF2794NjUaDadOmYdy4cXb+GOoqrXDHP3/ob3m963/ByP6tJe72v4icK9VXARl7z3GkHO0KRz4O5Wx4feTtPngnAKBbh4toe1NibNu6BMVXPbA3oz0A4Kcjd+BamTsC215p5InRuUelb2tBRZPJhKFDh9q9HuODDz6IpKQky3LjtUlJScG5c+eQnp6ODRs2YMWKFbhw4cLthKc6H++r6ND6N5wq8Kn2vlH/O/oFmZGS2U2lyJwDr4/9jp9pg7O5BgzqdRZajYjBvc+gvFKH0xd85D/szKQ/RqZvdThli3HChAmWRwJtSUpKki1zY1lxW7Zu3Ypx48ZBq9XCx8cHI0aMwPbt2/HUU0/JftaZuGkFvPnQTvz3aDecKWxd7dyYu4/j/7KNyP5Nf4tPN328PnUjSlqk/dgFf3/ya3i4C6gUtJj/3ghcK2/k+y011q600t1Y6yXIjUYjcnNzFY2hvjSQ8Nror1Eh6PDGVzUfmRxzzwms3dtXhcicA69P3fULycaMv+zDc2+F48S5Nuh2xyW8Hp2Gl5f/P5y64Kt2eLet0c5jfPjhh5WMowmQsDDsG/h6X8XMLx5CpairdrZ3gBl+LUqw43hHleJTG6/P7egcVIBfTrbD8bNVI/THzrZFZpYf+oVkN+rE2CTvMTqC0WistgS52WxGu3btVIyobuaN2IWOPpcxa9NolFXW/Hsz9p7j2HmiI65WeKgQnfp4fWzTaUV4uFVCq5Wg00rwcKuETivi2Nm26NElF52DqvZC7tL+Enp2zsXp7EZ+jxFo/PMYlRAWFobk5GSMGjUKRUVF2Llzp133L52BUf87Hu2dibJKHb55+iPL+/E7hmLrr13hoavEqG6n8eJ/XXN6E6+PvIkPHcQTY/7P8nrUwFP4MKUvPkrph49S+mHhjJ3w0Zei6HcvfLKtNw5kBtmorRFw8nuMGkmBXa0WL16M9PR0XLp0Ca1bt4bBYMCWLVswdepUPPvss+jRowcEQUB8fDz27NkDAJg6dSoiIyPr/F2jXnsfOZevNPSPQC6i9YlK+UIurJ2fHslrp9e7nvv/tRbZV2z/ngbq9dg1VZ3BV0USo5KYGKk+mBhta7DEuMbOxDhNncRo1z3G8vJyvPPOO3jwwQfRr18/AMD333+PTz75xKHBEVHTJDeH0Z5Ra0eyKzG+/vrrOHHiBJYtW2aZ29ilSxd89tlnDg2OiJqoG6PScodK7Bp82blzJ9LT0+Ht7W152sXf3x95eXkODY6ImignH3yxKzG6u7tDEIRq7xUWFsJgMDgkKCJq2jSwY4K3IpHUzq6udFhYGF555RWcP38eAJCfn4/4+Hg89NBDDg2OiJomjWjfoRa7EuPzzz+PoKAgjB07FleuXEFoaCj8/Pwwc+ZMR8dHRE2R3ORuZ11E4mYeHh6IjY1FbGwsCgsL0bp1a7sWmCAiqpUD7jE+88wzuHDhArRaLby9vfH3v/8dISEhyMrKQkxMDIqKimAwGJCQkIDg4GCbddmVGG90oW8oKSmx/Lt9+/Z1i56IXJ4jFpFISEhAy5YtAVQNGMfGxmLTpk2YP38+JkyYgIiICHz55ZeIi4vDunXrbNZl9wreGo2m2rapN1qMv/76a92iJyJygBtJEQCKi4uh0WhQUFCAzMxMfPjhhwCA8PBwLFq0CIWFhfDxufXz5nYlxmPHjlV7ffHiRaxcudKudRaJiGqoQ1fabDbXmBWj1+uh19dct3Pu3LnYs2cPJEnC2rVrYTab4e/vD52uajUnnU4HPz8/mM3m+idGa23btsXcuXMRGhqKMWPG3E4VROTCNJL8qPONrnRUVBSys7OrnYuOjsasWbNqfOa1114DAGzevBlLlizB7Nmzbyu+215d53//+x9KS0tv9+NE5Mrq0GJMSkqqtcVoy5///GfExcWhXbt2yMvLgyAI0Ol0EAQB+fn5MBqNNj9vV2K03uagtLQUp06d4nQdIro99jwLff28XBIDqgaEr1y5Yin79ddfo1WrVvD19UVISAhSU1MRERGB1NRUhISE2OxGA3YmRuttDpo1a4a77rpLdsibiKhWDTxdp7S0FLNnz0ZpaSm0Wi1atWqFxMREaDQaLFiwADExMVi9ejX0ej0SEhJk65NNjIIg4KeffsKiRYvg4eGaqysTUcNq6Ok6bdq0wcaNG2s916lTJyQnJ9chOjsSo06nw549ezihm4gajnj9kCujErseCZw8eTJWrFiBiooKR8dDRC7A2ddjtNliTE1NRXh4OD755BNcunQJH374IXx8fKq1Hr/99ltHx0hETZET7x1gMzHGxcUhPDwcS5cuVSoeInIFjXk9xhuPAN57772KBENErsERz0o3JJuJURRF/PTTT7C1X9Z9993X4EERURPXmFuM5eXlmDt37i0To0ajwVdffeWQwIio6bJnIVo1F6q1mRibNWvGxEdEDa8xtxiJiBxBA/k9XdScOW3X4AsRUYNqzC3GgwcPKhUHEbkQZ98lkF1pIlJeY24xEhE5QqMelSYicgi2GImIrNRhoVo1NLnE6Lf2Z0hnL6odhlOSBvVSOwSnF7Zmt9ohODW9uz+A6fWviC1GIqLqGvWz0kREDiFBfiFaJkYiciVsMRIRWeM9RiKi6jSSBI3MI8dy5x2JiZGIlMcWIxFRdbzHSERkRSPZ8UggEyMRuRR2pYmIqmNXmojIWgO3GC9fvoyXX34Z586dg4eHBzp06ID4+Hj4+Pjg0KFDiIuLQ1lZGQIDA7F06VL4+vrarE9r/1cTETWMGy1GucPu+jQaPPXUU0hLS0NKSgrat2+PZcuWQRRFzJkzB3FxcUhLS4PJZMKyZctk62NiJCLliRI0MgdE+zOjwWDAgAEDLK979+6NnJwcZGRkwNPTEyaTCQAwfvx4bN++XbY+dqWJSHl16EqbzWYIglDtlF6vh16vr/Vjoijis88+w/Dhw2E2mxEQEGA55+PjA1EUUVRUBIPBcMuvZmIkIsXVZbpOVFQUsrOzq52Ljo7GrFmzav3cokWL4O3tjcceeww7duy4rfiYGIlIeXVoMSYlJdXaYqxNQkICzp49i8TERGi1WhiNRuTk5FjOFxYWQqvV2mwtAkyMRKSCukzXMRqNdtX59ttvIyMjA2vWrIGHhwcAoHv37rh27RoOHDgAk8mE9evXIywsTLYuJkYiUp4kVR1yZex08uRJvPfeewgODsb48eMBAEFBQVi1ahWWLFmC+fPnV5uuI4eJkYgU19C7BHbp0gXHjx+v9Vzfvn2RkpJSh+iYGIlIBXzyhYioBju60io+LM3ESESKY4uRiMgaV9chIqqOLUYiImuCVHXIlVEJEyMRKY4tRiKiGjgqTURUnT3rLbLFSEQuhaPSRETVaQRAIzO4ohFsnnYoJkYiUpxGkqCRuccod96RmBgd4OUVZ9F7cDG8vEVczndD8j/9sP1T25vvNHVjw45h1LDTCL7jMr79/k4sW/WnGmWi/noYk8cfxisLR+DgkYBaamna9j3ujd9+0UGjq3rt6S9iSGoJCvfpsP9Jb+i8/igbMu8aAiMq1Am0IbArbXsHr5uVlpbi1VdfxdGjR6HT6fDKK69g2LBhSoTYoDas8Mc7L7ZHRbkW7Ttfw5LPT+PUkWY4dcRb7dBUU3C5GT79vAf69c6Bp0fNPpLR/3fcf99ZFBQ2UyE65xESew1Bf62Z8Dz9JDzwVbEKETmKc49KK7IZ1q128LL2/vvvo0WLFtixYwcSExMxb948lJSUKBFigzp7wgsV5VWX9saycwHB5SpHpa49ezvgh/134PffPWs9H/3UXqz9pC8qKrk/myto6F0CG5oi/xfeagcva9u2bUNkZCQAIDg4GN27d8euXbuUCLHBRb9+AV+e/gXv7z6Ownx37PuqpdohOa0h951BRaUW+w8GqR2K6k4s98TXg1tg72PeKNyns7xfXqDBN/e3wK7QFjiW4InKqyoG2RButBjkDpUofo/x5h28rOXk5CAwMNDy2mg0Ijc3V8nwGszK2CCsnheIEFMJet5XYmlBUnXNvCowZcJBxMSPVDsU1XV9oQwtOgnQugPmbe74v2hvDPq8GM07ihj0nxI0v1NEaY4GGXOb4fhSL9wz/5raId82jSDZMSrdxLvSN7t5B6+mThQ1OLqvBdoaKxA++ZLa4TiliY8exs7vOiLvYgu1Q1GdoacAt+aA1gMIjKiAoY+Ai7vd4NlGQotOIjRawDtIQtcXypC3o5GPm0p2HipR9Opa7+BlLSAgANnZ2ZZBGbPZXK0L3lhp3SQYO7j2PcZb6dPDjDa+VzEmtGpZ+lb6Msx9YRc2ftkdGzd3Vzk6dWk0ACRNLScASazl/UaE03Wuq20HL2thYWHYsGEDevTogTNnzuDIkSN46623lAqxQbTyrUDvwcXYu0OP8mta9BnyO4b9uQhvPHOH2qGpSqsVodNJ0GqrDnd3AYKgwcsLR8LN7Y9fgJVvbkHiv03YfzDQRm1NT8UV4LcjOrQ2CdDogNztbrj8sw53xVxDwT4dvINEeBklXMvV4MQ7nvAb3oin6gBw9lFpRRKjrR28IiIisGbNGvj7++PJJ59ETEwMRo4cCa1Wi/j4eLRo0ci6WJIG4ZMK8OybF6DRAvkXPJAYF4Cf0lupHZmqov76CyY++ovl9Yih/8PHG3vi4429q5UTRA2Kiz1w7Zq70iGqSqrU4OQ/vFCSpYVGBzS/U0Dv5VfRPFjExe88cCSmGSquaODRSoLfgxXoMrtM7ZDrR7x+yJVRiUaSVGyvOsBjdz6DvLMX1Q7DKUmDeqkdgtMLW7Nb7RCcmt7dH9O6rKt3PZPGvos88282y/gbW2Hdf5+r93fdjkZ+B5eIGiVRAkSZJqHYxLvSRETVOHlXmomRiBSngR2j0k39kUAiomoc8ORLQkIChg8fjm7duuHEiROW97OyshAZGYnQ0FBERkbizJkzsnUxMRKR8hyQGB988EEkJSVVe3oOAObPn48JEyYgLS0NEyZMQFxcnGxdTIxEpLwbuwTKHXVgMplgNBqrvVdQUIDMzEyEh4cDAMLDw5GZmYnCwkKbdfEeIxEpz44nX260GM1mMwSh+lJ1er0eer1e9mvMZjP8/f2h01UtyKHT6eDn5wez2Vxj2cObMTESkfLs6SpfPx8VFYXs7Oxqp6KjozFr1ixHRcfESEQqkCA/T/H66aSkpFpbjPYwGo3Iy8uDIAjQ6XQQBAH5+fk1utzWmBiJSHl1aDHKJTFbfH19ERISgtTUVEYPsSAAAAnISURBVERERCA1NRUhISE2u9EAEyMRqaEOidFeixcvRnp6Oi5duoQnnngCBoMBW7ZswYIFCxATE4PVq1dDr9cjISFBti4mRiJSniBWHXJl6mDevHmYN29ejfc7deqE5OTkOtXFxEhEypPEqkOujEqYGIlIBVyPkYioOhHyo9JcRIKIXIoDBl8aEhMjESmPiZGIyIogVB1yZVTCxEhEKuDgCxFRdexKExFZ4ag0EZEVSYTECd5ERDdxwCOBDYmJkYiUJ4ny26eyxUhELoWDL0RE1UmiBEmmxSjJDc44EBMjESmPLUYiIiuiZMd0HSZGInIhkihAknnkTxL5SCARuRJJsmOhWrYYG0ybQNub3LgyqV0rtUNwenp3f7VDcGot3No0SD2+Aa1lB1d8A1o3yHfdDo0kqZiWiYickFbtAIiInA0TIxGRFSZGIiIrTIxERFaYGImIrDAxEhFZYWIkIrLCxEhEZIWJkYjIChNjPWVlZSEyMhKhoaGIjIzEmTNnapQRBAELFy7EiBEjMHLkSCQnJysfqEoSEhIwfPhwdOvWDSdOnKi1jCtfn8uXL2Pq1KkIDQ3FmDFjEB0djcLCwhrlSktL8dxzz2HkyJEICwvDN998o0K0LkSiepk4caK0efNmSZIkafPmzdLEiRNrlNm0aZM0ZcoUSRAEqaCgQBoyZIh0/vx5pUNVxf79+6WcnBxp2LBh0vHjx2st48rX5/Lly9JPP/1kef3mm29Kr776ao1yK1askObOnStJkiRlZWVJgwYNkoqLixWL09WwxVgPBQUFyMzMRHh4OAAgPDwcmZmZNf7ib926FePGjYNWq4WPjw9GjBiB7du3qxGy4kwmE4xGo80yrnx9DAYDBgwYYHndu3dv5OTk1Ci3bds2REZGAgCCg4PRvXt37Nq1S7E4XQ0TYz2YzWb4+/tDp9MBAHQ6Hfz8/GA2m2uUCwgIsLw2Go3Izc1VNFZnxutTRRRFfPbZZxg+fHiNczk5OQgMDLS8dtVrpBQmRiInsWjRInh7e+Oxxx5TOxSXx8RYD0ajEXl5eRCur0QsCALy8/NrdB2NRmO17pHZbEa7du0UjdWZ8fpUDVKdPXsW7777LrTamr+WAQEByM7Otrx2xWukJCbGevD19UVISAhSU1MBAKmpqQgJCYGPT/XFcsPCwpCcnAxRFFFYWIidO3ciNDRUjZCdkqtfn7fffhsZGRlYtWoVPDw8ai0TFhaGDRs2AADOnDmDI0eOYMiQIUqG6VK4UG09nT59GjExMbhy5Qr0ej0SEhLQsWNHTJ06Fc8++yx69OgBQRAQHx+PPXv2AACmTp1quZHe1C1evBjp6em4dOkSWrduDYPBgC1btvD6XHfy5EmEh4cjODgYXl5eAICgoCCsWrUKERERWLNmDfz9/XH16lXExMTg119/hVarxZw5czBixAiVo2+6mBiJiKywK01EZIWJkYjIChMjEZEVJkYiIitMjEREVpgYyW4xMTF45513AAAHDhxQbK5ht27dcPbs2VrPTZw40e7VeIYPH44ffvjhtmKoz2ep8WFibGKGDx+Onj17ok+fPhg0aBBiYmJQUlLS4N9jMpmQlpYmW+6LL77A3/72twb/fiJHYmJsghITE3Hw4EFs2rQJGRkZ+Oc//1mjTGVlpQqRETUOTIxNmL+/P4YMGYKTJ08CqOqSJiUlYdSoURg1ahQA4JtvvkFERARMJhPGjx+PY8eOWT6fmZmJhx9+GH369MFzzz2HsrIyy7m9e/fi/vvvt7w2m82Ijo7GwIEDMWDAAMTHx+P06dOYP38+Dh06hD59+sBkMgEAysvLkZCQgAceeACDBg1CXFwcrl27Zqlr7dq1GDx4MAYPHozPP//c7p/33LlzmDRpEgYMGIABAwbgxRdfxJUrV6qVOXLkCEaPHo3+/fvj1VdfrfYz2boW5FqYGJsws9mMXbt2ISQkxPLezp07sXHjRmzduhWZmZmIjY1FfHw89u7di8jISDzzzDMoLy9HeXk5Zs6ciYiICOzbtw9hYWFIT0+v9XsEQcD06dMREBCAr7/+Grt27cLo0aPRqVMnLFy4EL1798bBgwdx4MABAMCyZcuQlZWFzZs3Iz09Hfn5+Vi1ahUAYNeuXfjggw/wwQcfID09HT/++KPdP68kSZg+fTp2796Nbdu2ITc3FytWrKhWJiUlBe+//z527NiBrKwsrF69GgBsXgtyPUyMTdDMmTNhMpkwYcIE9O/fHzNmzLCcmzZtGgwGA7y8vLBhwwZERkaiV69e0Ol0ePjhh+Hu7o5Dhw7h8OHDqKiowOTJk+Hu7o6wsDD06NGj1u/75ZdfkJ+fj5dffhne3t7w9PS0tA6tSZKEjRs3IjY2FgaDAS1atMD06dOxZcsWAFULsj7yyCPo2rUrvL29ER0dbffP3aFDB/zpT3+Ch4cHfHx88MQTT2D//v3VykRFRcFoNMJgMODpp5+2fK+ta0Gux03tAKjhrVq1CoMGDar13M1LouXk5GDz5s345JNPLO9VVFQgPz8fGo0G/v7+0Gg0lnM3LyZ7sxsLzbq5yf/vVFhYiNLSUjzyyCOW9yRJgiiKAID8/Hx0797dcu7mxVnlXLp0Ca+99hoOHDiAkpISSJIEvV5frczNP39AQADy8/MB2L4W5HqYGF3MzYnOaDRixowZePrpp2uU27dvH/Ly8iBJkuUzOTk5aN++fY2yRqMRZrMZlZWVNZLjzd8HAK1bt4aXlxe2bNkCf3//GnVZr4Be2zL/t/L2229Do9EgJSUFBoMBO3fuRHx8fLUy1nX7+flZfoZbXQtyPexKu7Bx48Zh/fr1OHz4MCRJwtWrV/Htt9+iuLgYvXv3hpubG9atW4eKigqkp6fjyJEjtdbTs2dPtG3bFm+99RauXr2KsrIy/PzzzwCq1qzMy8uz3KvTarUYN24cXn/9dRQUFAAA8vLysHv3bgBV6w5u2rQJp06dQmlpKVauXGn3z1NSUgJvb2+0bNkSeXl5WLt2bY0yn376KXJzc1FUVITExESMHj1a9lqQ62FidGE9evTAokWLEB8fj/79+2PUqFH44osvAAAeHh5YsWIFNm3ahHvvvRdbt27FyJEja61Hp9MhMTERZ8+exbBhw3D//fdj27ZtAICBAweic+fOGDx4sGXTpzlz5qBDhw549NFH0bdvXzz++OPIysoCAAwdOhSTJ0/G5MmTMXLkSAwcONDunyc6OhqZmZkwmUyYNm2aZeT9ZuHh4ZgyZQpGjBiBO+64w9JCtHUtyPVwPUYiIitsMRIRWWFiJCKywsRIRGSFiZGIyAoTIxGRFSZGIiIrTIxERFaYGImIrDAxEhFZ+f9HZkNATMcl5AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRBCrG0g7rVW"
      },
      "source": [
        "#### Analyzing **Decision Trees**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "plku1Joy79bq",
        "outputId": "3d60a7eb-23e7-4950-b26d-0ef657d06ee8"
      },
      "source": [
        "clf_DT(X_Data, Y_Lavel, 'BloodPressure')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.72      0.67        72\n",
            "         1.0       0.45      0.23      0.31        73\n",
            "         2.0       0.53      0.70      0.60        73\n",
            "\n",
            "    accuracy                           0.55       218\n",
            "   macro avg       0.53      0.55      0.53       218\n",
            "weighted avg       0.53      0.55      0.52       218\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[52 12  8]\n",
            " [19 17 37]\n",
            " [13  9 51]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5504587155963303\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.60      0.59        72\n",
            "         1.0       0.35      0.34      0.34        73\n",
            "         2.0       0.60      0.60      0.60        72\n",
            "\n",
            "    accuracy                           0.51       217\n",
            "   macro avg       0.51      0.51      0.51       217\n",
            "weighted avg       0.51      0.51      0.51       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[43 25  4]\n",
            " [23 25 25]\n",
            " [ 7 22 43]]\n",
            "\n",
            "Accuracy for Current Fold: 0.511520737327189\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.53      0.52        73\n",
            "         1.0       0.30      0.33      0.31        72\n",
            "         2.0       0.52      0.42      0.46        72\n",
            "\n",
            "    accuracy                           0.43       217\n",
            "   macro avg       0.44      0.43      0.43       217\n",
            "weighted avg       0.44      0.43      0.43       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[39 27  7]\n",
            " [27 24 21]\n",
            " [12 30 30]]\n",
            "\n",
            "Accuracy for Current Fold: 0.42857142857142855\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.59      0.58        73\n",
            "         1.0       0.36      0.42      0.39        72\n",
            "         2.0       0.48      0.39      0.43        72\n",
            "\n",
            "    accuracy                           0.47       217\n",
            "   macro avg       0.47      0.46      0.47       217\n",
            "weighted avg       0.47      0.47      0.47       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[43 21  9]\n",
            " [21 30 21]\n",
            " [12 32 28]]\n",
            "\n",
            "Accuracy for Current Fold: 0.46543778801843316\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.62      0.58        72\n",
            "         1.0       0.34      0.26      0.30        72\n",
            "         2.0       0.56      0.60      0.58        73\n",
            "\n",
            "    accuracy                           0.50       217\n",
            "   macro avg       0.48      0.50      0.49       217\n",
            "weighted avg       0.48      0.50      0.49       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[45 21  6]\n",
            " [24 19 29]\n",
            " [13 16 44]]\n",
            "\n",
            "Accuracy for Current Fold: 0.4976958525345622\n",
            "\n",
            "\n",
            "---------------------Average---------------------\n",
            "Accuracy (Avg. +/- Std.) is  0.491 +/- 0.041\n",
            "Avg. CM is [[35, 36], [36, 107]]\n",
            "Total for all folds CM is [[533, 553], [553, 1619]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqySfVdpCoE3"
      },
      "source": [
        "#### Analyzing **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "20CxA0gqCyQm",
        "outputId": "c2d82d99-8004-478c-bfdf-82794b7ce26d"
      },
      "source": [
        "clf_RF(X_Data, Y_Lavel, 'BloodPressure')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.88      0.85        72\n",
            "         1.0       0.65      0.53      0.59        73\n",
            "         2.0       0.67      0.74      0.70        73\n",
            "\n",
            "    accuracy                           0.72       218\n",
            "   macro avg       0.71      0.72      0.71       218\n",
            "weighted avg       0.71      0.72      0.71       218\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[63  7  2]\n",
            " [ 9 39 25]\n",
            " [ 5 14 54]]\n",
            "\n",
            "Accuracy for Current Fold: 0.7155963302752294\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.85      0.78        72\n",
            "         1.0       0.68      0.47      0.55        73\n",
            "         2.0       0.71      0.82      0.76        72\n",
            "\n",
            "    accuracy                           0.71       217\n",
            "   macro avg       0.71      0.71      0.70       217\n",
            "weighted avg       0.71      0.71      0.70       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[61  8  3]\n",
            " [18 34 21]\n",
            " [ 5  8 59]]\n",
            "\n",
            "Accuracy for Current Fold: 0.7096774193548387\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.92      0.78        73\n",
            "         1.0       0.62      0.47      0.54        72\n",
            "         2.0       0.73      0.65      0.69        72\n",
            "\n",
            "    accuracy                           0.68       217\n",
            "   macro avg       0.68      0.68      0.67       217\n",
            "weighted avg       0.68      0.68      0.67       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[67  5  1]\n",
            " [22 34 16]\n",
            " [ 9 16 47]]\n",
            "\n",
            "Accuracy for Current Fold: 0.6820276497695853\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.82      0.78        73\n",
            "         1.0       0.70      0.61      0.65        72\n",
            "         2.0       0.73      0.75      0.74        72\n",
            "\n",
            "    accuracy                           0.73       217\n",
            "   macro avg       0.73      0.73      0.73       217\n",
            "weighted avg       0.73      0.73      0.73       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[60  9  4]\n",
            " [12 44 16]\n",
            " [ 8 10 54]]\n",
            "\n",
            "Accuracy for Current Fold: 0.728110599078341\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.81      0.79        72\n",
            "         1.0       0.57      0.53      0.55        72\n",
            "         2.0       0.68      0.71      0.70        73\n",
            "\n",
            "    accuracy                           0.68       217\n",
            "   macro avg       0.68      0.68      0.68       217\n",
            "weighted avg       0.68      0.68      0.68       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[58 11  3]\n",
            " [13 38 21]\n",
            " [ 3 18 52]]\n",
            "\n",
            "Accuracy for Current Fold: 0.6820276497695853\n",
            "\n",
            "\n",
            "---------------------Average---------------------\n",
            "Accuracy (Avg. +/- Std.) is  0.703 +/- 0.019\n",
            "Avg. CM is [[50, 21], [21, 123]]\n",
            "Total for all folds CM is [[764, 322], [322, 1850]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObS0nyN5H1qb"
      },
      "source": [
        "#### Analyzing **AdaBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BXwutgp4H8uw",
        "outputId": "39b00f1d-3e70-4eba-b0f5-e1e915221655"
      },
      "source": [
        "clf_AB(X_Data, Y_Lavel, 'BloodPressure')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.83      0.72        72\n",
            "         1.0       0.48      0.34      0.40        73\n",
            "         2.0       0.56      0.55      0.55        73\n",
            "\n",
            "    accuracy                           0.57       218\n",
            "   macro avg       0.56      0.57      0.56       218\n",
            "weighted avg       0.56      0.57      0.56       218\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[60  9  3]\n",
            " [19 25 29]\n",
            " [15 18 40]]\n",
            "\n",
            "Accuracy for Current Fold: 0.573394495412844\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.76      0.72        72\n",
            "         1.0       0.42      0.34      0.38        73\n",
            "         2.0       0.56      0.60      0.58        72\n",
            "\n",
            "    accuracy                           0.57       217\n",
            "   macro avg       0.55      0.57      0.56       217\n",
            "weighted avg       0.55      0.57      0.56       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[55 11  6]\n",
            " [20 25 28]\n",
            " [ 6 23 43]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5668202764976958\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.77      0.67        73\n",
            "         1.0       0.46      0.29      0.36        72\n",
            "         2.0       0.59      0.64      0.61        72\n",
            "\n",
            "    accuracy                           0.57       217\n",
            "   macro avg       0.55      0.57      0.55       217\n",
            "weighted avg       0.55      0.57      0.55       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[56  9  8]\n",
            " [27 21 24]\n",
            " [10 16 46]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5668202764976958\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.60      0.58        73\n",
            "         1.0       0.42      0.44      0.43        72\n",
            "         2.0       0.59      0.50      0.54        72\n",
            "\n",
            "    accuracy                           0.52       217\n",
            "   macro avg       0.52      0.52      0.52       217\n",
            "weighted avg       0.52      0.52      0.52       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[44 23  6]\n",
            " [21 32 19]\n",
            " [14 22 36]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5161290322580645\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.71      0.67        72\n",
            "         1.0       0.47      0.50      0.49        72\n",
            "         2.0       0.59      0.49      0.54        73\n",
            "\n",
            "    accuracy                           0.57       217\n",
            "   macro avg       0.57      0.57      0.56       217\n",
            "weighted avg       0.57      0.57      0.56       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[51 14  7]\n",
            " [18 36 18]\n",
            " [11 26 36]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5668202764976958\n",
            "\n",
            "\n",
            "---------------------Average---------------------\n",
            "Accuracy (Avg. +/- Std.) is  0.558 +/- 0.021\n",
            "Avg. CM is [[40, 32], [32, 112]]\n",
            "Total for all folds CM is [[606, 480], [480, 1692]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI8OmhDlIt-f"
      },
      "source": [
        "#### Analyzing **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UfxRBIB4IdgW",
        "outputId": "31fe5c4a-c12d-4684-b2aa-eda3eb717db6"
      },
      "source": [
        "clf_NB(X_Data, Y_Lavel, 'BloodPressure')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.86      0.68        72\n",
            "         1.0       0.58      0.15      0.24        73\n",
            "         2.0       0.46      0.56      0.51        73\n",
            "\n",
            "    accuracy                           0.52       218\n",
            "   macro avg       0.53      0.52      0.48       218\n",
            "weighted avg       0.53      0.52      0.47       218\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[62  2  8]\n",
            " [22 11 40]\n",
            " [26  6 41]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5229357798165137\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.52      0.81      0.63        72\n",
            "         1.0       0.47      0.12      0.20        73\n",
            "         2.0       0.55      0.67      0.60        72\n",
            "\n",
            "    accuracy                           0.53       217\n",
            "   macro avg       0.52      0.53      0.48       217\n",
            "weighted avg       0.52      0.53      0.48       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[58  3 11]\n",
            " [36  9 28]\n",
            " [17  7 48]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5299539170506913\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.81      0.64        73\n",
            "         1.0       0.47      0.11      0.18        72\n",
            "         2.0       0.51      0.62      0.56        72\n",
            "\n",
            "    accuracy                           0.52       217\n",
            "   macro avg       0.50      0.51      0.46       217\n",
            "weighted avg       0.50      0.52      0.46       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[59  2 12]\n",
            " [32  8 32]\n",
            " [20  7 45]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5161290322580645\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.49      0.73      0.59        73\n",
            "         1.0       0.58      0.15      0.24        72\n",
            "         2.0       0.50      0.62      0.56        72\n",
            "\n",
            "    accuracy                           0.50       217\n",
            "   macro avg       0.52      0.50      0.46       217\n",
            "weighted avg       0.52      0.50      0.46       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[53  1 19]\n",
            " [35 11 26]\n",
            " [20  7 45]]\n",
            "\n",
            "Accuracy for Current Fold: 0.5023041474654378\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.52      0.79      0.63        72\n",
            "         1.0       0.36      0.18      0.24        72\n",
            "         2.0       0.54      0.52      0.53        73\n",
            "\n",
            "    accuracy                           0.50       217\n",
            "   macro avg       0.47      0.50      0.46       217\n",
            "weighted avg       0.47      0.50      0.47       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[57  5 10]\n",
            " [36 13 23]\n",
            " [17 18 38]]\n",
            "\n",
            "Accuracy for Current Fold: 0.4976958525345622\n",
            "\n",
            "\n",
            "---------------------Average---------------------\n",
            "Accuracy (Avg. +/- Std.) is  0.514 +/- 0.012\n",
            "Avg. CM is [[37, 35], [35, 109]]\n",
            "Total for all folds CM is [[558, 528], [528, 1644]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkLrc60EJA6i"
      },
      "source": [
        "#### Analyzing **XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U4c2mzLpI9vd",
        "outputId": "7e69509e-1e7e-447f-9497-7e6f66521b27"
      },
      "source": [
        "clf_XGB(X_Data, Y_Lavel, 'BloodPressure')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.83      0.80        72\n",
            "         1.0       0.66      0.60      0.63        73\n",
            "         2.0       0.68      0.68      0.68        73\n",
            "\n",
            "    accuracy                           0.71       218\n",
            "   macro avg       0.70      0.71      0.70       218\n",
            "weighted avg       0.70      0.71      0.70       218\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[60  8  4]\n",
            " [10 44 19]\n",
            " [ 8 15 50]]\n",
            "\n",
            "Accuracy for Current Fold: 0.7064220183486238\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.78      0.77        72\n",
            "         1.0       0.61      0.56      0.59        73\n",
            "         2.0       0.71      0.75      0.73        72\n",
            "\n",
            "    accuracy                           0.70       217\n",
            "   macro avg       0.69      0.70      0.69       217\n",
            "weighted avg       0.69      0.70      0.69       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[56 13  3]\n",
            " [13 41 19]\n",
            " [ 5 13 54]]\n",
            "\n",
            "Accuracy for Current Fold: 0.695852534562212\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.81      0.72        73\n",
            "         1.0       0.53      0.46      0.49        72\n",
            "         2.0       0.72      0.64      0.68        72\n",
            "\n",
            "    accuracy                           0.64       217\n",
            "   macro avg       0.63      0.64      0.63       217\n",
            "weighted avg       0.63      0.64      0.63       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[59 10  4]\n",
            " [25 33 14]\n",
            " [ 7 19 46]]\n",
            "\n",
            "Accuracy for Current Fold: 0.6359447004608295\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.74      0.72        73\n",
            "         1.0       0.61      0.54      0.57        72\n",
            "         2.0       0.67      0.69      0.68        72\n",
            "\n",
            "    accuracy                           0.66       217\n",
            "   macro avg       0.66      0.66      0.66       217\n",
            "weighted avg       0.66      0.66      0.66       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[54 13  6]\n",
            " [14 39 19]\n",
            " [10 12 50]]\n",
            "\n",
            "Accuracy for Current Fold: 0.6589861751152074\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.78      0.76        72\n",
            "         1.0       0.68      0.71      0.69        72\n",
            "         2.0       0.70      0.64      0.67        73\n",
            "\n",
            "    accuracy                           0.71       217\n",
            "   macro avg       0.71      0.71      0.71       217\n",
            "weighted avg       0.71      0.71      0.71       217\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[56  8  8]\n",
            " [ 9 51 12]\n",
            " [10 16 47]]\n",
            "\n",
            "Accuracy for Current Fold: 0.7096774193548387\n",
            "\n",
            "\n",
            "---------------------Average---------------------\n",
            "Accuracy (Avg. +/- Std.) is  0.681 +/- 0.029\n",
            "Avg. CM is [[49, 23], [23, 121]]\n",
            "Total for all folds CM is [[740, 346], [346, 1826]]\n",
            "Sensitivity (Avg. +/- Std.) is  0.681 +/- 0.103\n",
            "Specificity (Avg. +/- Std.) is  0.841 +/- 0.028\n",
            "Precision (Avg. +/- Std.) is  0.679 +/- 0.060\n",
            "FOR (Avg. +/- Std.) is  0.158 +/- 0.045\n",
            "DOR (Avg. +/- Std.) is  14.033 +/- 8.105\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruw9L1ZkwMkO"
      },
      "source": [
        "# With Glucose as Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PqLKfiGzNqd"
      },
      "source": [
        "def categorize_GL(data_GL):\n",
        "    #Oral glucose tolerance test\n",
        "    GL = \"Glucose\"\n",
        "    try:\n",
        "        low_i = data_GL.loc[(data_GL[GL] <= 70)] # low\n",
        "        normal_i = data_GL.loc[(data_GL[GL] > 70) & (data_GL[GL] < 140)] #prediabetic\n",
        "        high_i =  data_GL.loc[data_GL[GL] >= 140] #high\n",
        "\n",
        "        data_GL[GL][low_i.index] = 0\n",
        "        data_GL[GL][normal_i.index] = 1\n",
        "        data_GL[GL][high_i.index] = 2\n",
        "     \n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return data_GL"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSpX-Hw-wpEI",
        "outputId": "32b05374-4fb1-4c25-dd46-74caa80189ff"
      },
      "source": [
        "data_GL = swap_col('Glucose')\n",
        "print(data_GL.head()), data_GL.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Diabetic  ...   Age  Glucose\n",
            "0          6.0         1  ...  50.0    148.0\n",
            "1          1.0         0  ...  31.0     85.0\n",
            "2          8.0         1  ...  32.0    183.0\n",
            "3          1.0         0  ...  21.0     89.0\n",
            "4          5.0         0  ...  30.0    116.0\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, (636, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6j5iDfuaorf"
      },
      "source": [
        "data_GL = categorize_GL(data_GL)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "mEbDhdY132NS",
        "outputId": "06b4cc3d-029a-413f-9398-36390e417a5c"
      },
      "source": [
        "#Augmentation\n",
        "smote = SMOTE()\n",
        "X = np.array(data_GL.iloc[:,0:8])\n",
        "y = np.array(data_GL.iloc[:,8])\n",
        "X, y = smote.fit_resample(X, y)\n",
        "data_GL = pd.DataFrame(X)\n",
        "data_GL['Glucose'] = y\n",
        "data_GL.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>Glucose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>33.600000</td>\n",
              "      <td>0.627000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>26.600000</td>\n",
              "      <td>0.351000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>32.059259</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>23.300000</td>\n",
              "      <td>0.672000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>28.100000</td>\n",
              "      <td>0.167000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>27.094512</td>\n",
              "      <td>113.606695</td>\n",
              "      <td>25.600000</td>\n",
              "      <td>0.201000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1447</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>87.788945</td>\n",
              "      <td>32.059259</td>\n",
              "      <td>171.474227</td>\n",
              "      <td>34.604020</td>\n",
              "      <td>0.292910</td>\n",
              "      <td>44.316583</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1448</th>\n",
              "      <td>5.912418</td>\n",
              "      <td>0.456209</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>27.963813</td>\n",
              "      <td>119.260634</td>\n",
              "      <td>40.529150</td>\n",
              "      <td>0.419017</td>\n",
              "      <td>50.193464</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1449</th>\n",
              "      <td>9.672367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>32.375521</td>\n",
              "      <td>162.910208</td>\n",
              "      <td>34.011116</td>\n",
              "      <td>0.572632</td>\n",
              "      <td>47.017102</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1450</th>\n",
              "      <td>1.141011</td>\n",
              "      <td>0.070505</td>\n",
              "      <td>72.141011</td>\n",
              "      <td>21.779737</td>\n",
              "      <td>168.244952</td>\n",
              "      <td>25.945476</td>\n",
              "      <td>0.138652</td>\n",
              "      <td>24.352527</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1451</th>\n",
              "      <td>4.974482</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>63.897927</td>\n",
              "      <td>32.846891</td>\n",
              "      <td>324.821373</td>\n",
              "      <td>31.192345</td>\n",
              "      <td>0.571951</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1452 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1          2  ...         6          7  Glucose\n",
              "0     6.000000  1.000000  72.000000  ...  0.627000  50.000000      2.0\n",
              "1     1.000000  0.000000  66.000000  ...  0.351000  31.000000      1.0\n",
              "2     8.000000  1.000000  64.000000  ...  0.672000  32.000000      2.0\n",
              "3     1.000000  0.000000  66.000000  ...  0.167000  21.000000      1.0\n",
              "4     5.000000  0.000000  74.000000  ...  0.201000  30.000000      1.0\n",
              "...        ...       ...        ...  ...       ...        ...      ...\n",
              "1447  7.000000  1.000000  87.788945  ...  0.292910  44.316583      2.0\n",
              "1448  5.912418  0.456209  78.000000  ...  0.419017  50.193464      2.0\n",
              "1449  9.672367  1.000000  94.000000  ...  0.572632  47.017102      2.0\n",
              "1450  1.141011  0.070505  72.141011  ...  0.138652  24.352527      2.0\n",
              "1451  4.974482  1.000000  63.897927  ...  0.571951  29.000000      2.0\n",
              "\n",
              "[1452 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAtsyAOOCFJb",
        "outputId": "423b71e9-220d-4df3-879f-5b253a55ee9d"
      },
      "source": [
        "data_GL.Glucose.value_counts()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    484\n",
              "1.0    484\n",
              "2.0    484\n",
              "Name: Glucose, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCrUBu0CCFJc"
      },
      "source": [
        "data_GL.columns = ['F' + str(i) for i in range(1,9)]+['Outcome'] #Renaming"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLo5e6rbDwPn"
      },
      "source": [
        "X_Data,Y_Lavel = feature_Selector(data_GL, algo='None', n_feature=8)  "
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-evipCEhS6Cb"
      },
      "source": [
        "#### Analyzing **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGR3mjBFS6Cr",
        "outputId": "1e85c4b5-4ee1-4cc1-f63f-4803062746cb"
      },
      "source": [
        "clf_KNN(X_Data, Y_Lavel, 'Glucose')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      1.00      0.96        97\n",
            "         1.0       0.91      0.70      0.79        97\n",
            "         2.0       0.79      0.91      0.85        97\n",
            "\n",
            "    accuracy                           0.87       291\n",
            "   macro avg       0.87      0.87      0.87       291\n",
            "weighted avg       0.87      0.87      0.87       291\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[97  0  0]\n",
            " [ 6 68 23]\n",
            " [ 2  7 88]]\n",
            "\n",
            "Accuracy for Current Fold: 0.8694158075601375\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.99      0.96        97\n",
            "         1.0       0.94      0.68      0.79        97\n",
            "         2.0       0.77      0.94      0.85        97\n",
            "\n",
            "    accuracy                           0.87       291\n",
            "   macro avg       0.88      0.87      0.87       291\n",
            "weighted avg       0.88      0.87      0.87       291\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[96  0  1]\n",
            " [ 5 66 26]\n",
            " [ 2  4 91]]\n",
            "\n",
            "Accuracy for Current Fold: 0.8694158075601375\n",
            "\n",
            "--------------------------------------------------\n",
            "Detailed classification report for current fold:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.96      0.94        96\n",
            "         1.0       0.87      0.62      0.72        97\n",
            "         2.0       0.74      0.93      0.82        97\n",
            "\n",
            "    accuracy                           0.83       290\n",
            "   macro avg       0.85      0.83      0.83       290\n",
            "weighted avg       0.85      0.83      0.83       290\n",
            "\n",
            "\n",
            "\n",
            "Confusion Matrix for current fold: \n",
            "[[92  3  1]\n",
            " [ 6 60 31]\n",
            " [ 1  6 90]]\n",
            "\n",
            "Accuracy for Current Fold: 0.8344827586206897\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyXUwkHFDzMQ"
      },
      "source": [
        "#clf_KNN(X_Data, Y_Lavel, 'Glucose')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPs3Ksk5B8tZ"
      },
      "source": [
        "all_clf_res['BloodPressure']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vGBC_OpTUVh"
      },
      "source": [
        "#### Analyzing **Decision Trees**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXIvuFNyTUVh"
      },
      "source": [
        "clf_DT(X_Data, Y_Lavel, 'Glucose')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voo0Cm09TUVi"
      },
      "source": [
        "#### Analyzing **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5dbju9xTUVi"
      },
      "source": [
        "clf_RF(X_Data, Y_Lavel, 'Glucose')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9dDOrzmTUVj"
      },
      "source": [
        "#### Analyzing **AdaBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXNHLhI2TUVj"
      },
      "source": [
        "clf_AB(X_Data, Y_Lavel, 'Glucose')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYt1DfSdTUVj"
      },
      "source": [
        "#### Analyzing **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZJmrlB0TUVk"
      },
      "source": [
        "clf_NB(X_Data, Y_Lavel, 'Glucose')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qonY4zaqTUVk"
      },
      "source": [
        "#### Analyzing **XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcCdpaKYTUVk"
      },
      "source": [
        "clf_XGB(X_Data, Y_Lavel, 'Glucose')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNm5XLjbgICM"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoWT8X5yTowz"
      },
      "source": [
        "row_index = ['BloodPressure', 'Glucose']\n",
        "model_names = ['KNN', 'DecisionTree', 'RandomForest', 'AdaBoost', 'NaiveBayes', 'XGBoost']\n",
        "results = pd.DataFrame(all_clf_res['BloodPressure'], index = model_names)\n",
        "results['Glucose'] = all_clf_res['Glucose']\n",
        "results = results.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQkn5K84UwfB"
      },
      "source": [
        "results.index = row_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0A9DjmvWmux"
      },
      "source": [
        "print(\"Multiclass\")\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7bUCaxzEbpQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}