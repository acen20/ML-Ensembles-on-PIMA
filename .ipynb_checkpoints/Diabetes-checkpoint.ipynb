{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# sns.set(style=\"whitegrid\")\n",
    "import warnings \n",
    "from sklearn.svm import SVC, NuSVC\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors  import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "# from tflearn.data_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import interp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZWa0WB5N06M",
    "outputId": "61e06f99-b08e-42aa-dfa9-bb814755667f"
   },
   "outputs": [],
   "source": [
    "## Make 1 or True  if you run colab\n",
    "## Other wise 0 or False\n",
    "##if you run in  colab\n",
    "\n",
    "colab = 0\n",
    "if colab ==True:\n",
    "  data_dir='/content/drive/MyDrive/PIMA Journal/diabetes.csv'\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "else:\n",
    "  \n",
    "  data_dir='Diabetes_processed.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPXAbwA7Olty"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "fsEN6pCHOtDa",
    "outputId": "19be9b44-5c7d-4543-d845-94dee5a500f2"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FBYD-y5pmde"
   },
   "outputs": [],
   "source": [
    "def swap_col(target_):\n",
    "  swap_data = copy.deepcopy(data)\n",
    "  swap_data[target_] = data.Outcome\n",
    "  swap_data.Outcome = data[target_]\n",
    "  swap_data.rename(columns = {'Outcome':target_, target_: 'Diabetic'}, inplace = True)\n",
    "  swap_data.Diabetic.replace({1:'Yes', 0:'No'} , inplace = True)\n",
    "  return swap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EcVLsoXqcT0"
   },
   "outputs": [],
   "source": [
    "data_BP = swap_col('BloodPressure')\n",
    "data_GL = swap_col('Glucose')\n",
    "data_ST = swap_col('SkinThickness')\n",
    "data_Ins = swap_col('Insulin')\n",
    "data_BMI = swap_col('BMI')\n",
    "data_DPF = swap_col('DiabetesPedigreeFunction')\n",
    "data_Age = swap_col('Age')\n",
    "data_Pregnancies = swap_col('Pregnancies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_BP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clf_res=[]                    #every classifier auc values are stored in it\n",
    "random_initializer=100            #random initializer\n",
    "n_dots=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_Model (classifier, X_Train, Y_Train, tuned_parameters, verbose):\n",
    "\n",
    "    clf = GridSearchCV(classifier,\n",
    "                    tuned_parameters,\n",
    "                    verbose=verbose,\n",
    "                    cv=5,\n",
    "                    scoring='f1',\n",
    "                    n_jobs=-1)\n",
    "    clf.fit(X_Train, Y_Train)\n",
    "    return clf\n",
    "    ############################################################\n",
    "    \n",
    "def feature_Selector(data, algo, n_feature):\n",
    "\n",
    "    if algo=='PCA':                                                   #for pca algorithm\n",
    "        X_Data= data.iloc[:,:8].values\n",
    "        pca = PCA(n_components=n_feature)                             #number of feature\n",
    "        X_Data = pca.fit_transform(X_Data)\n",
    "        return X_Data , data.iloc[:,8:].values\n",
    "\n",
    "    if algo == 'ICA':\n",
    "        X_Data= data.iloc[:,:8].values\n",
    "        ICA = FastICA(n_components=n_feature, random_state=12) \n",
    "        X_Data = ICA.fit_transform(X_Data)\n",
    "        return X_Data , data.iloc[:,8:].values\n",
    "    \n",
    "    if algo =='corr':                                                   #for ica algorithm\n",
    "        if n_feature ==4:\n",
    "            data = data[['F2','F5','F4','F6','Outcome']]                #for 4 feature\n",
    "            return data.iloc[:,:4].values, data.iloc[:,4:].values\n",
    "        if n_feature ==6:\n",
    "            data = data[['F1','F2','F4','F5','F6','F8','Outcome']]       #for 6 feature\n",
    "            return data.iloc[:,:6].values, data.iloc[:,6:].values\n",
    "        \n",
    "    if algo == 'None':\n",
    "        return data.iloc[:,:8].values, data.iloc[:,8:].values            #if feature selection is off all features are counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=random_initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With BloodPressure as Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "Sr1VI20Utwf6",
    "outputId": "26739c77-8fb9-4390-dfa5-aa0782f9cd09",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_BP.head(), data_BP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_heartrate(data_BP):\n",
    "    \n",
    "    BP = \"BloodPressure\"\n",
    "    try:\n",
    "        norm_i = data_BP.loc[(data_BP[BP] >= 60) & (data_BP[BP] <= 100)]\n",
    "        low_i = data_BP.loc[data_BP[BP] < 60]\n",
    "        high_i =  data_BP.loc[data_BP[BP] > 100]\n",
    "\n",
    "        \n",
    "        data_BP[BP][low_i.index] = 1\n",
    "        data_BP[BP][norm_i.index] = 2\n",
    "        data_BP[BP][high_i.index] = 3\n",
    "     \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return data_BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_BP = categorize_heartrate(data_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_BP.BloodPressure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_BP.columns = ['F' + str(i) for i in range(1,9)]+['Outcome'] #Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Data,Y_Lavel = feature_Selector(data_BP, algo='corr', n_feature=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(Y_Lavel,return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Accuracy = []                                                                # for store the value of accuracy                                                               # for store the values of auc\n",
    "iterator=0\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "for train_index, test_index in kf.split(X_Data,Y_Lavel):                     # split in train and test\n",
    "    #   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_Train, X_Test = X_Data[train_index], X_Data[test_index]                #train data and label\n",
    "    Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]              #test data and label\n",
    "\n",
    "    ###########################################\n",
    "    # define the hyper parameters of Knn\n",
    "    n_neighbors = [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49]\n",
    "    leaf_size = [5,10,15,20,25,30,35,40,45,50]\n",
    "    Distance = [1,2]\n",
    "    ############################################\n",
    "\n",
    "\n",
    "    tuned_parameters = [ {'n_neighbors': n_neighbors,                         #define parameters with different algorithm\n",
    "                        'algorithm' : ['brute'],\n",
    "                        'p':Distance},\n",
    "\n",
    "                         {'n_neighbors': n_neighbors, \n",
    "                        'algorithm' : ['ball_tree'],\n",
    "                        'leaf_size' : leaf_size,\n",
    "                        'p':Distance},\n",
    "\n",
    "                        {'n_neighbors': n_neighbors, \n",
    "                        'algorithm' : ['kd_tree'],\n",
    "                        'leaf_size' : leaf_size,\n",
    "                        'p':Distance}]\n",
    "\n",
    "    clf = creat_Model (classifier = KNeighborsClassifier(),                     #create the model \n",
    "                      X_Train = X_Train,\n",
    "                      Y_Train = Y_Train,\n",
    "                      tuned_parameters = tuned_parameters,\n",
    "                      verbose=0)\n",
    "    iterator += 1\n",
    "    Accuracy.append(accuracy_score(Y_Test, clf.predict(X_Test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Diabetes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
